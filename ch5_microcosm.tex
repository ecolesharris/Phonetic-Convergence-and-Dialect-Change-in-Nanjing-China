\chapter{Explaining Participants' Experiment-External Mandarinization: An Experimental Microcosm}
\label{microcosmchapter}
The experimental protocol adopted for this dissertation was designed as it was in an attempt to serve as a microcosmic mirror of a potential mechanism for real-world contact-induced dialect change. This chapter describes why participants adopted features of the shadowing model's speech to the degree that they did, and then relates those facts to their participation in sound changes currently in progress in Nanjing Dialect.

While, as discussed in chapter \ref{internalchapter}, the group as a whole did not significantly adopt features from the shadowing model into their Nanjing Dialect over the course of the experiment, individuals' tendencies towards either convergence with or divergence from Mandarin norms---in both experimental and real-world contexts---are well predicted by a mix of \hl{socio-psychological}, linguistic, and demographic factors. The fact that both can be predicted by overlapping sets of factors suggests that the experiment was at least partly successful in recreating the dynamics of contact-induced change in a laboratory setting, lending some support both to the idea that such a thing can be done, and to the specific methodology adopted here. Additionally, the fact that the there is considerable overlap between sets of factors that predict generalization and Mandarinization suggests first that the Mandarinization results are not merely a fluke, and second that the specific set of factors investigated here are reasonable candidates for predictors of participation in sound change outside the laboratory.

\section{Modeling Participant Generalization and Mandarinization}
\label{sec:genAndMandModels}
Stuff
\subsection{Dependent Variables}
Two measures of dialect change were calculated for each of the five linguistic variables under investigation to serve as dependent variables: \hl{``generalization''} and ``Mandarinization.'' Both of these measures are speaker- and word-internal measures. The \hl{generalization} measure was calculated for each Nanjing Dialect post-test token by subtracting from it the Nanjing Dialect baseline pronunciation of the same word by the same participant. Mandarinization was likewise calculated for Nanjing Dialect baseline tokens by subtracting from them their respective Mandarin baseline pronunciations.\footnote{As an interesting side note, the effects described in this chapter are not visible in across-participant measures of generalization and Mandarinization. This suggests that speaker normalization may play a role in dialect change. \hl{Give more detail and make sure you believe this.}}\hl{Why the \textbf{difference between} ...}Using the difference between a given token and a reference point allows these measures to tell us the direction and magnitude of change in pronunciation after exposure to another dialect (in the case of generalization) or the distance between an individual speaker's Mandarin and Nanjing Dialect pronunciations (in the case of Mandarinization) while accounting for individual and lexical variation.%Predicting participants' raw acoustic measures in the post-test is not useful, because a measure may be equally predictable in the pre- and post-tests whether there was any change at all.

\hl{Are generalization and Mandarinization really good parallels for real world sound change?} Generalization is a reasonably good parallel for what Trudgill \citeyearpar{trudgill1986dialects} calls ``long-term accommodation,'' in that it is an example of a persistent change in one's speech style after exposure to a different style. During the experiment, participants' exposure to both their own baseline Mandarin and the shadowing model's hyper-standard Mandarin \hl{cause changes that persist} into in the Nanjing Dialect post-test. That's exactly the dynamic we're investigating \IRL.\footnote{\hl{Is that true?} Am I comfortable saying that their Nanjing Dialect was ``caused'' to change by this exposure? Or that the apparent changes to their dialect are ``persisting'' from what happens in the shadowing block?}\hl{How do we deal with the fact that this could technically be either ``Mandarinization'' or ``Nanjing Dialect-ization?''} My measure of Mandarinization is also good, because it's a measure of the difference in pronunciation between the two dialects, and even though it's intra-personal we can be confident that since Nanjing dialect has been getting more and more Mandarin-y \IRL~\citep{bao1980sixty}, it's not unreasonable to assume that a lack of difference between the Nanjing Dialect and Mandarin of a speaker who self-reports fluency in both (as all participants in this experiment did) is due to the Nanjing Dialect having merged with the Mandarin, rather than the other way around.

\subsection{Independent Variables}
\hl{What were the predictors?} Nine independent variables were used to predict participant behavior at the individual level:

\begin{enumerate}
    \item History
    \item Use
    \item Proficiency
    \item Explicit Attitudes
    \item Implicit Attitudes
    \item Imitation Score
    \item Age
    \item Gender
    \item Education
\end{enumerate}

 \hl{Why this set of variables?}
Imitation---though it is usually more commonly referred to as ``accommodation'' in these contexts---has become sort of the \textit{de facto} explanation for what's going on in contact-induced dialect change. Trudgill \citeyear{trudgill1986dialects,trudgill2008colonial,trudgill2008on} argues that in \textit{tabula rasa} new dialect formation situtations, the numerically dominant dialectal variant is \hl{sure to be} the form that the new dialect eventually adopts, due to \hl{XXXXX} via interpersonal accommodation. \hl{Who else? Thomason \& Kaufmann? Others? Check synthesis.} The prevalence of this view was actually a big part of the reason that I designed this experiment as a shadowing experiment, because I wanted to take a relatively straightforward measure of imitation and see what it told us about how people participate in sound change. \hl{There are probably other reasons I've forgotten momentarily}.

Likewise, the BLP's History, Use, Proficiency, and Explicit Attitude measures were chosen as potential predictors of participation in sound change because \hl{[AUTHOR]} has hypothesized such a dominance measure be a good predictor of participation in sound change \hl{(CITATION)}. I broke apart the dominance measure into its component pieces because I wanted to be able to directly compare speakers' self-reported Explicit Attitudes and their implicit attitudes as measured by the Implicit Associations Task---IAT scores \hl{having been found to significantly influence} speakers' average convergence with an interlocutor in a shadowing task \citep{babel2010dialect}.

It has also been suggested \hl{(by whom)} that age, gender, education, \hl{and other demographic factors} can affect interpersonal accommodation, and potentially thereby participation in sound change. Beyond that, age and education level \hl{almost certainly} affect how Nanjing Dialect speakers specifically participate in sound change\hl{... at least, they affect how these people speak Nanjing Dialect} \citep{bao1980sixty} (\hl{and maybe} \citealp{xu2006nanjing}?).

\hl{How did you get these numbers?}
All of these factors except implicit attitudes and imitation score were obtained via this experiment's version of the Bilingual Language Profile. See chapter \ref{methodchapter} for a detailed description of the protocol used here, and Appendix \ref{appendix:BLP} for the full English text of that survey. Implicit attitudes were measured via an Implicit Associations Task (``IAT;'' \citealp{greenwald1998measuring,greenwald2003understanding}), also described in Chapter \ref{methodchapter}. Finally, an imitation score was calculated for each participant by generating a linear mixed-effects model for each individual predicting their subset of Mandarin VOT durations by experimental condition (pre-test versus shadowing) with a random effect for word, and taking the \textit{t}-value for the condition predictor as that individual's ``imitation score.''

While the \textit{t}-value from a model predicting an individual's raw duration in the shadowing versus the pre-test condition is not technically a measure of ``imitation'' \textit{per se}, it is preferable to using a measure like difference-in-distance (``DiD;'' see \citealp{babel2010dialect,babel2012evidence}) because it avoids the pitfalls of making a direct acoustic comparison between the participant and the model talker, which would be especially problematic for nasality measures. It is also not entirely clear whether speakers generally imitate the raw acoustic signal or patterns of meaningful change \citep{zellou2016phonetic}, which can affect \hl{stuff}. I'm avoiding DiD \hl{like the plague} because \hl{it's not really useful for A1-P0 and I want all my ling variables to be comparable}. Using the \textit{t}-value is sufficient for our purposes because the  model talker's VOTs are \hl{virtually always} longer than participant Mandarin baselines.\footnote{Mean durations for the model and the participants' Mandarin baselines are 184 ms and 93 ms, respectively. Only one of the model's tokens is shorter than 93 ms; her doubled VOT for the second p in the word ``pipei''is 43 ms. the model's next shortest duration is 128 ms.}The sign of the \textit{t}-value indicates whether a participant's VOTs lengthened or shortened from the Mandarin baseline to the shadowing condition, and thereby whether the participant converged with or diverged from the model's much longer VOTs on the whole. At the same time, the magnitude of the \textit{t}-value serves as a composite measure of the magnitude and consistency of any change in VOT duration, such that those who very consistently lengthened their VOT, even if not by much, would have a greater positive imitation score.

Imitation score was only calculated based on participants VOT, and not based on their behavior while shadowing nasal coda words. \hl{While it would have been desirable to have a measure of imitation in nasality,..., whereas imitation in VOT is relatively straightforward}. Additionally, using change in VOT as the only measure of imitation and predicting participant behavior in all five linguistic variables by that single per-participant number helps to maximize the comparability and interpretability of the predictive models.\footnote{\hl{What does it mean that Sub2/5/8/11/12/23/26/29/30's mean PTH baseline VOT duration is \textit{shorter} than their mean ND baseline VOT duration? Which (if any) of those above are significant?}}

\subsection{Building the Models} 
For each linguistic variable under investigation, two comprehensive linear mixed-effects models were created, one predicting \hl{generalization} and one predicting Mandarinization, by the nine independent variables described above, along with a random effect for word \hl{(which I think I need, even though gen and mand are within-word measures, because that only deals with lexical variation in the pronunciation of the word, while including a random effect for word here should be helping me deal with any variation in how the words pronunciation varies \textit{from condition to condition})}. Each comprehensive model was then compared to 9 deficient models---each missing one of the independent variables---in likelihood ratio tests. These tests determine the significance of each predictor within the comprehensive models. Tables \ref{tab:generalizationPredictors} and \ref{tab:mandarinizationPredictors} give the results of those likelihood ratio tests. The results of these tests indicate that overlapping sets of independent variables predict generalization and Mandarinization better than null models lacking the members of those sets. There is variation in which particular independent variables are significant predictors of the dependent variable among the various linguistic variables investigated, as well as variation in which and how many of the linguistic variables a given independent variable is significant for, but overall there \hl{seem to be} patterns of which linguistic variables are most predictable, and which predictors are most significant across linguistic variables in both generalization and Mandarinization. \hl{How can I prove it?}

\begin{table}[]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        this will be & a copy of \\
        \hline
        the tables in & my numbers spreadsheet\\
        \hline
    \end{tabular}
    \caption{Pull the stuff about gen prediction from Diss Math Summ sheet 2}
    \label{tab:generalizationPredictors}
\end{table}

\begin{table}[]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        this will be & a copy of \\
        \hline
        the tables in & my numbers spreadsheet\\
        \hline
    \end{tabular}
    \caption{Pull the stuff about mand prediction from Diss Math Summ sheet 2}
    \label{tab:mandarinizationPredictors}
\end{table}

\section{Results}
There are five main points to be made here:
\begin{enumerate}
    \item it is possible to predict a speaker's Mandarinization \IRL;
    \item it is also (mostly) possible to predict a speaker's generalization;
    \item there are specific independent variables that seem like good options for predicting participation in sound change, either in future experiments, or in real world contexts;
    \item parallels in the predictability of generalization and Mandarinization indicate both that the present experimental paradigm is useful for examining sound change and that the successful prediction of Mandarinization \IRL~described in this dissertation was not a fluke; and
    \item while there's a compelling case for the parallels mentioned in point 4 above, there is also considerable variation in the predictability of the various linguistic variables considered here, and in how predictive the various independent variables are.
\end{enumerate}

\paragraph{To the first point:}

Mandarinization was significantly predicted by at least one independent variable for all five linguistic variables. \hl{This box may be checked, but obvy more needs to be said...} Out of the 45 likelihood ratio tests conducted to determine the significance of predictors of Mandarinization, 15 were significant. The specific set of independent variables that were significant was different for each of the linguistic variables, but there was always something that predicted the behavior.

\hl{Tell me which predictors are significant for which linguistic/dependent variables}. See table \ref{tab:sigMandPredEsts} for detailed information on what the estimates and all that were for these.

\begin{table}[]
    \centering
    \begin{tabular}{|cccccc|}
        \hline
         & VOT (sec) & NAS ($\Delta$Hz) & IY (Hz) & IE (Hz) & LN (Hz)\\
        \hline
        History & -8.653e-04 & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        Use & \cellcolor{lightgray} & -0.048707 & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        Proficiency & 8.196e-04 & -0.059113 & -5.42373 & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        Explicit & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & -5.506 \\
        IAT Score & 1.034e-02 & \cellcolor{lightgray} & 129.56726 & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        Imitation & 1.257e-03 & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        Age & -2.066e-03 & \cellcolor{lightgray} & 8.69309 & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        Gender & \cellcolor{lightgray} & -2.529635 & \cellcolor{lightgray} & 198.2252 & \cellcolor{lightgray} \\
        Education & 5.170e-03 & 0.480499 & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        \hline
    \end{tabular}
    \caption{Estimates for significant predictors of Mandarinization.}
    \label{tab:sigMandPredEsts}
\end{table}

\hl{Do the Mandarinization prediction estimates go the way you'd expect? I haven't quite figured that out yet... I'm confused about what the signs of the estimates actually mean. I'll figure that out.}

\paragraph{To the second point:}
All of the generalization linguistic variables except \degdip~were significantly predicted by at least one independent variable. Of the 45 likelihood ratio tests for generalization, 6 were significant. The specific set of independent variables that were significant was different for each of the linguistic variables, but there was always something that predicted the behavior.

\hl{Tell me which predictors are significant for which linguistic/dependent variables}. See table \ref{tab:sigGenPredEsts} for detailed information on what the estimates and all that were for these.

\begin{table}[]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
         & VOT (sec) & NAS ($\Delta$Hz) & IY (Hz) & IE (Hz) & LN (Hz)\\
        \hline
        History & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        \hline
        Use & \cellcolor{lightgray} & 0.023375 & \cellcolor{lightgray} & \cellcolor{lightgray} & -4.6666 \\
        \hline
        Proficiency & -5.965e-04 & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        \hline
        Explicit & \cellcolor{lightgray} & -0.063778 & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        \hline
        IAT Score & \cellcolor{lightgray} & \cellcolor{lightgray} & -44.2634 & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        \hline
        Imitation & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & 16.4647 \\
        \hline
        Age & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        \hline
        Gender & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        \hline
        Education & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} & \cellcolor{lightgray} \\
        \hline
    \end{tabular}
    \caption{Estimates for significant predictors of Mandarinization.}
    \label{tab:sigGenPredEsts}
\end{table}

\paragraph{To the third point:}
All of the independent variables were significant in at least one of the comprehensive models, but some were significant in a bunch of the models, and therefore seem like better (\hl{or at least pretty good?}) candidates for further research into sound change prediction. Proficiency, as reported via the Bilingual Language Profile \citep{birdsong2012bilingual, gertken2014assessing}, was significant for four of the comprehensive models, the largest number of any independent variable. It was useful in predicting VOT generalization, VOT Mandarinization, NAS Mandarinization, and IY Mandarinization. Of the independent variables that I've used here, this is probably the best bet for future studies that want to try to predict either experimental or real-world participation in sound change. As a reminder, proficiency means basically, ``how good do I think I am at speaking Nanjing Dialect/Mandarin?'' (\hl{prolly more detail here})...

The middling predictors---Use and IAT score with 3; Explicit Attitudes, Age, Gender, and Education with 2 each---are just that. \hl{I'm not really sure what sort of point there is to be made about these as a group.} They all work sometimes, but aren't the \emph{most} worky.

History was significant in the smallest number of comprehensive models---just one, VOT Mandarinization. VOT Mandarinization, remember, was the comprehensive model that had the most significant predictors, likely because it's dependent variable is closest to the acoustic dimension along which speakers actually maintain phonological and social distinctions. It's possible that history would be significant for other dependent variables if those variables were closer parallels of what speakers really care about. Just as a note, the estimate for change in the dependent variable as a result of a single unit increase in History is $-8.653e-04$seconds, or just under one millisecond shorter. This makes sense, given that more positive History rankings are defined as being more Nanjing Dialect dominant, and Nanjing Dialect in general has shorter VOTs than Mandarin.

\hl{Should I talk about the fact that the most and least significant predictors are both elements of the BLP's dominance score? Or that the dominance measures are sort of inconsistent generally? By that I mean, of the four dominance measures, one has 4 sig spots, one 3, one 2, and one 1.}

\paragraph{To the fourth point:}
Granted, fewer of the independent variables are significant predictors of generalization than they are of Mandarinization, and the set of significant variables are not totally overlapping, but that doesn't mean that generalization and Mandarinization are not comparable. I argue that what this tells us is that the experiment is not a \emph{perfect} microcosm of real world sound change, but it is still a microcosm. A paired two tail \textit{t}-test does not suggest that there is a significant difference in the \textit{p}-values of each of the generalization likelihood ratio tests as compared to their matching Mandarinization likelihood ratio tests, either for all of the generalization and mandarinization models, or for any particular linguistic variable's generalization versus mandarinization. \hl{The results were} $t = 0.98242, df = 44, p-value = 0.3313$. Sure, that's not \emph{quite} the same as saying they're the same, but its at least saying that generalization versus Mandainization are just super obviously different.

Of the 6 significant predictor variables from the generalization models, 3 were also significant for the Mandarinization models. Specifically, VOT.Proficiency, NAS.Use, and IY.IAT were significant in both sets of models. Not only that, but they also \hl{usually}\footnote{\hl{IY.IAT has results pointing in opposite directions from each other. I'm not sure what to do about that re: my claim here.}}had estimates that pointed in the same direction (more or less Mandarin-y). See Table \ref{tab:sigInBothEstimates}.

\begin{table}[]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Predictor Variable} & \textbf{Generalization} & \textbf{Mandarinization}\\
        \hline
        VOT.Proficiency & $-5.965e-04$sec (less) & $8.196e-04$sec (less) \\ % less mandariny in both cases (or more properly less different from Mandarin in the second case), but that makes sense w/ move towards ND dominance
        \hline
        NAS.Use &  $0.02$Hz (more) & $-0.048707$Hz (more) \\
        \hline
        \hl{IY.IAT} &  $-44$Hz (more)& $0.779268$Hz (less, \hl{contradictory}) \\
        \hline
    \end{tabular}
    \caption{Estimates of change in response variable for a 1-unit increase in predictor variable for predictors that are significant in both generalization and Mandarinization. The first two have estimates that point in the same direction. The last one has estimates pointing in opposite directions.}
    \label{tab:sigInBothEstimates}
\end{table}

\hl{Why does the flipped sign actually mean the \emph{same} thing between the conditions?} The numbers in Table \ref{tab:sigInBothEstimates} might be counter intuitive, cuz I said their estimates ``\hl{usually} pointed in the same direction,'' but the signs of the generalization estimates and their Mandarinization counterparts aren't the same except for in IY.IAT (which is actually the case where the results \emph{don't} suggest a parallel). This is because of how generalization and Mandarinization are calculated, and because of what I mean when I say something is ``more'' or ``less Mandarin-y.'' Generalization is the difference between the Nanjing Dialect post-test and the Nanjing Dialect pre-test, and so the calculation of generalization doesn't actually make reference to Mandarin at all. BUT, because there's a significant difference between Mandarin and Nanjing Dialect for all of these variables, I'm claiming that if, for example, your VOT gets longer from pre- to post-test, that's ``more Mandarin-y'' because it's motion in the direction of the difference between the baseline dialects as whole entities. At the same time, Mandarinization is calculated by taking the difference between the Nanjing Dialect baseline and the Mandarin baseline, assuming that \hl{...I need to fix this crazy sign flipping issue.}

\paragraph{To the fifth point:}
Most of the independent variables that are significant for one of either the generalization or Mandarinization prediction models for a given linguistic variable are \emph{not} significant in the other dependent variable for the matching linguistic variable model.

There are no independent variables that are significant for all linguistic variable models, even within a dependent variable set.

The interpretation of a single independent variable is also complicated and sometimes apparently contradictory across linguistic \hl{or dependent} variables.

All that means that while participation in sound change is predictable to a certain extent, there's no magic bullet amongst these factors for predicting who's going to participate the most. Also, 

\section{Discussion}
\label{sec:microcosmDiscussion}

This experiment gives us at least a little bit more information about how we might be able to predict sound change. Predicting our measure of Mandarinization \IRL~by the factors that we do in this experiment allows us to say something about who's most likely to participate in a particular sound change, though it may not tell us when or exactly how that person is likely to participate. At the same time, the predictability of generalization---that is, experimentally induced ``long-term'' sound change---suggests that it makes sense to try to design experimental methodologies to get at the when and how of predicting sound change \IRL.

The relative robustness of a certain set of predictors combined with the lack of difference in robustness between generalization and Mandarinization suggests that there is a subset of predictor variables that are particularly good bets for being able to predict sound change in other contexts, as well as good candidates for follow-up research. If future research helps us figure out more about why these predictors vary in the ways that they do, we can probably figure out better who's going to participate in sound change.

\hl{everything past here is just notes}

\pagebreak

Page intentionally left blank

\pagebreak


\hl{If mandarinization IRL is predictable, you should be able to tell who's going to change, tho not necessarily when or how.}

\hl{If generalization is predictable, then maybe it makes sense to try to design experimental methodologies to get at the when and how.}

\hl{The goodness of the predictors will be helpful for designing those methodologies, as long as you take the variation into account.}

The fact that the significant predictors across generalization and Mandarinization are \hl{largely} overlapping and the fact that there is not a significant difference between the matched \textit{p}-values across the generalization and Mandarinization models, are indications that the mechanisms of sound change are reasonable objects of study for laboratory phonologists.

\hl{Different ling variables have between 0 and 4 significant predictors for generalization, but between 1 and 6 for Mandarinization}.

\hl{Only Use is significant for more than one of the ling variables (specifically NAS and LN) in generalization}.

\hl{Imitation and Education are not significant for anything in the generalization models, tho they are for VOT (both) and NAS (just Education) in Mandarinization. Explicit is not significant for anything in mand, but is for NAS in gen}.

\hl{Proficiency and Age are significant for the largest number of ling variable models (3)}.

\hl{N}

There are a number of possible explanations for the general pattern of weaker significance in the prediction of generalization. One is that Mandarinization and generalization are not comparable measures, and that the experiment is apples while real-world sound change is oranges. Another possible explanation is that the measures \emph{are} substantively similar, and should be similarly predictable, but are so to different degrees. I will argue for the second explanation.

First, consider table \ref{tab:totalSigDependentByLing}, which displays the total predictive power (as measured by number of significance code stars) of each of the ten comprehensive models (5 linguistic variables $\times$ 2 dependent variables).

\begin{table}[]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
         & \textbf{Generalization} & \textbf{Mandarinization}\\
        \hline
        VOT & 3 & 18\\
        \hline
        NAS & 3.2 & 9.1\\
        \hline
        IY & 1.1 & 7.1\\
        \hline
        IE & 0 & 1\\
        \hline
        LN & 5 & 4.2\\
        \hline
    \end{tabular}
    \caption{Total significance across all predictors for each of the comprehensive models.}
    \label{tab:totalSigDependentByLing}
\end{table}

\hl{Why is VOT so predictable in Mandarinization, but much less so in generalization?}

The very high significance of predictors of Manadarinization for VOT relative to the other linguistic variables---it is the most predictable and has nearly twice the number of stars that the second most predictable does---may be due to the relevance to real-world speakers of the acoustic dimension measured for the experiment. There are both phonological contrasts (/p/ versus /p\super{h}/) and dialectal contrasts (Mandarin versus Nanjing Dialect) whose boundaries are clearly demarcated along the acoustic dimension of VOT duration (\hl{CITATIONS}); i.e., duration seems to be \emph{the} acoustic correlate relevant to these categories in the real world. For the other linguistic variables, however, the measure used in this experiment may only be \emph{an} acoustic correlate. F3, for example, may not be the \emph{whole} of what speakers vary\slash listen for in contrasting /i/ and /y/ in Mandarin, or when contrasting their Mandarin /y/ with their Nanjing Dialect /y/.

One might expect this logic to carry over from the real world into the experimental measures of generalization, thereby predicting higher overall significance for the model predicting generalization for VOT, relative to the other linguistic variables. That, however, is not the case. VOT is only the third most significant among the generalization models. \hl{It seems likely that} because of the manipulation of VOT within the context of the experiment, noise may have been inadvertently introduced into what would have otherwise been a reasonably predictable system. It is possible that in a randomized controlled trial where one group of participants is exposed to manipulated VOT and another is not, the ranking of linguistic variables by predictability would be closer to fully parallel. This is a matter for further investigation.

\hl{Why is LN's ranking for predictability so different in Mandarinization versus generalization?}

A similar, though inverse, relationship may be visible in the relative predictability of LN generalization versus Mandarinization. LN is the most predictable of the generalization models, but the second-least predictable of the Mandarinization models. I do not currently have a verifiable explanation for why this might be. LN words were never subject to experimental manipulation, and so would have expected it to behave more consistently between experimental and real-world contexts. Anecdotally, I have found that LN has the highest levels of social recognition as a dialectal variant of the linguistic variables investigated here. In Labov's \citeyearpar{labov1971study} terms, failure to contrast /l/ and /n/ is a Nanjing Dialect stereotype, while the other variables are either indicators (\hl{VOT, NAS, IE}) or markers (\hl{IY}).

\hl{Which predictors are most helpful for Mandarinization (and generalization, but that's not the main point)? I need to answer this so that I can make an argument about what drives sound change.}

\section{The conceptual link between the experiment and the real world}
\label{sec:conceptLinkExpIRL}

\hl{What is the conceptual relationship between the shadowing and post-test bits of the experiment? Like, if we can predict how people are changing \textit{in the real world} based on the predictors discussed here, then what's even the point of having a shadowing/post-test bit at all?}

Conceptually, the experiment was meant to recreate sound change in a laboratory environment, and the results lend some validity both to the idea that such a thing can be done and to the specific methodology adopted here.

Possible general defense of laboratory phonolgy. Imitation is studied in the lab all the time (\hl{CITATIONS})---and far more abstract things, such as the mental representation of phonemes. Sure, there are differences between laboratory and real-world speech, but look at the fact that 

Defense of looking at sound change specifically, even though people have claimed that sound change can't be observed (\hl{CITATIONS}). I got encouraging results here. Parallels between this experiment and any other 

\pagebreak

everything past here is just notes

\pagebreak

\hl{observations re: number of stars in the summary tables}
\begin{itemize}
    \item NAS is second in both.
    \item IE is last in both.
    \item VOT is more significant than IY and IE in both.
    \item IY is more significant than IE in both.
    \item VOT and LN are in very different spots in the rankings across the models.
\end{itemize}



\subsection{By-predictor Analyses}
The point of the story here should be that those predictors that are most significant within and across generalization and 
\subsection{}
The idea here is that \hl{if accommodation leads mechanistically} to dialect change, there should be a strong link between how much people accommodate in the experiment (prolly, even though it's not exactly the way that things work in the real world) and the amount that people participate in real-world dialect change (i.e., ``Mandarinization''). To figure out whether this is the case---whether the experiment and the real world are parallel---I'm going to look at how well I can predict participants' ``tokengn'' (difference between ND post-test and ND baseline for a given word) by a set of independent variables, and their ``tokenms'' (difference between their ND baseline and the average Mandarin pronunciation (either across or within speakers, \hl{I haven't decided}) \hl{(not for a given word?)}) by that same set of independent variables. The prediction was done by creating an omnibus model of the style:

response variable $\sim$ history + use + proficiency + explicit attitudes + implicit attitudes + imitation score + age + gender + education + (1$|$word)

for each response variable. The omnibus model (for each variable) was then compared to 9 other models in likelihood ratio tests that removed a single independent variable to determine the usefulness of that variable within the omnibus model. Here are the results of those comparisons:

\begin{table}
\centering
 \begin{tabular}{|c||c|c|c|c|c|c|} 
 \hline
 \textbf{Variable removed} & \textbf{AIC$_{full}$} & \textbf{AIC$_{null}$} & $\chi^2$ & \textbf{DF} & \textbf{$p$-value} & \textbf{Significance}\\ [0.5ex] 
 \hline
  History & \multirow{9}{*}{-3845.2} & -3846.2 & 0.9403 & \multirow{9}{*}{1} & 0.3322 & \\ 
 \cline{1-1}\cline{3-4}\cline{6-7}
 Use &  & -3844.8 & 2.3407 &  & 0.126 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Proficiency &  & -3833.1 & 14.069 &  & 0.0001762 & ***\\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Explicit Attitudes &  & -3846.5 & 0.7086 &  & 0.3999 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Implicit Attitudes &  & -3846.1 & 1.1029 &  & 0.2936 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Imitation Score &  & -3847.2 & 0.0131 &  & 0.9089 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Age &  & -3846.2 & 1.0368 &  & 0.3086 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Gender &  & -3844.5 & 2.7004 &  & 0.1003 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Education &  & -3845.7 & 1.5355 &  & 0.2153 & \\
 \hline
\end{tabular}
\caption{VOT token generalization (ND post-test - ND baseline) prediction.}
\label{tab:VOTtokengnPredictors}
\end{table}

\begin{table}
\centering
 \begin{tabular}{|c||c|c|c|c|c|c|} 
 \hline
 \textbf{Variable removed} & \textbf{AIC$_{full}$} & \textbf{AIC$_{null}$} & $\chi^2$ & \textbf{DF} & \textbf{$p$-value} & \textbf{Significance}\\ [0.5ex] 
 \hline
  History & \multirow{9}{*}{12104} & 12103 & 1.1449 & \multirow{9}{*}{1} & 0.2846 & \\ 
 \cline{1-1}\cline{3-4}\cline{6-7}
 Use &  & 12102 & 0.0156 &  & 0.9005 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Proficiency &  & 12102 & 0.1822 &  & 0.6695 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Explicit Attitudes &  & 12102 & 0.4671 &  & 0.4943 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Implicit Attitudes &  & 12106 & 4.3547 &  & 0.03691 & *\\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Imitation Score &  & 12102 & 0.2842 &  & 0.594 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Age &  & 12102 & 0.2665 &  & 0.6057 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Gender &  & 12102 & 0.027 &  & 0.8694 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Education &  & 12105 & 3.1377 &  & 0.0765 & \\
 \hline
\end{tabular}
\caption{[i]/[y] token generalization (ND post-test - ND baseline) prediction.}
\label{tab:IYtokengnPredictors}
\end{table}

\begin{table}
\centering
 \begin{tabular}{|c||c|c|c|c|c|c|} 
 \hline
 \textbf{Variable removed} & \textbf{AIC$_{full}$} & \textbf{AIC$_{null}$} & $\chi^2$ & \textbf{DF} & \textbf{$p$-value} & \textbf{Significance}\\ [0.5ex] 
 \hline
  History & \multirow{9}{*}{13144} & 13142 & 0.235 & \multirow{9}{*}{1} & 0.6279 & \\ 
 \cline{1-1}\cline{3-4}\cline{6-7}
 Use &  & 13143 & 0.753 &  & 0.3855 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Proficiency &  & 13143 & 0.862 &  & 0.3532 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Explicit Attitudes &  & 13142 & 0.0244 &  & 0.8758 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Implicit Attitudes &  & 13144 & 1.4205 &  & 0.2333 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Imitation Score &  & 13142 & 0.009 &  & 0.9243 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Age &  & 13143 & 0.7922 &  & 0.3734 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Gender &  & 13142 & 0.2453 &  & 0.6204 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Education &  & 13142 & 0.072 &  & 0.7885 & \\
 \hline
\end{tabular}
\caption{[e]/[\textipa{iE}] token generalization (ND post-test - ND baseline) prediction.}
\label{tab:IEtokengnPredictors}
\end{table}

\begin{table}
\centering
 \begin{tabular}{|c||c|c|c|c|c|c|} 
 \hline
 \textbf{Variable removed} & \textbf{AIC$_{full}$} & \textbf{AIC$_{null}$} & $\chi^2$ & \textbf{DF} & \textbf{$p$-value} & \textbf{Significance}\\ [0.5ex] 
 \hline
  History & \multirow{9}{*}{13636} & 13640 & 6.3504 & \multirow{9}{*}{1} & 0.01174 & *\\ 
 \cline{1-1}\cline{3-4}\cline{6-7}
 Use &  & 13637 & 3.3712 &  & 0.06635 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Proficiency &  & 13636 & 1.7747 &  & 0.1828 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Explicit Attitudes &  & 13636 & 1.7627 &  & 0.1843 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Implicit Attitudes &  & 13635 & 0.7527 &  & 0.3856 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Imitation Score &  & 13636 & 1.6297 &  & 0.2017 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Age &  & 13636 & 2.124 &  & 0.145 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Gender &  & 13637 & 3.2996 &  & 0.0693 & \\
 \cline{1-1}\cline{3-4}\cline{6-7}
 Education &  & 13638 & 3.6672 &  & 0.05549 & \\
 \hline
\end{tabular}
\caption{[l]/[n] token generalization (ND post-test - ND baseline) prediction.}
\label{tab:LNtokengnPredictors}
\end{table}

\hl{Honestly, I have no idea what to do with these results. I'm supposed to be able to explain why things are the way they are, and I really just can't. None of variables (excluding possibly NAS/AN, since I haven't done it yet) behave the same way as any of the others. I imagine that the ``significant predictors'' are just noise in the signal being amplified by careless statistical methods.} For the dependent variables listed in the tables above, the only independent variables that ever appear to have any explanatory power are proficiency (in VOT), implicit attitudes (in IY), and history (in LN). The apparent effect of proficiency on VOT generalization is that a 1 point increase in proficiency score (that is, a 1 point shift towards greater proficiency in Nanjing Dialect) leads to a $5.974e-04$ second decrease in the difference between their Nanjing Dialect Baseline and their Nanjing Dialect post-test for VOT. That is, people who are more proficient in Nanjing Dialect either change their Nanjing Dialect less after exposure to Mandarin, or they start of with more mandarin-y ND to begin with (which would be counter-intuitive given their report of greater proficiency in ND). A 1 point increase in implicit bias towards Mandarin leads to 44.88829 Hz less difference between Nanjing Dialect Baseline and their Nanjing Dialect post-test for [i]/[y], meaning either 

\pagebreak
everything past here is just notes
\pagebreak

experiment-externally, is there a link between shadowing and Mandarinization?

I've got two different ways of talking about mandarinization: tokenms, and tokenpm

Even though overall there wasn't significant accommodation across the dialects (or ``generalization'' as I've occasionally called it), there \textit{are} differences in how Mandarinized participants are in their Nanjing Dialect baselines, which should serve as a reasonable proxy for how people participate in long-term cross-dialectal accommodation out in the real world.

People 

\section{Hypotheses Tested}
\label{sec:externalHypotheses}

Here are the specific hypotheses tested and reported in this chapter:

\begin{enumerate}
    \item Individuals' post-test behavior (in all variables) will be well predicted by linguistic \hl{(main)} and demographic factors.
    \item Individuals' baseline Nanjing Dialect Mandarinization (a proxy for real-world participation in sound change) will be well predicted by linguistic \hl{(main)} and demographic factors for all variables.
\end{enumerate}

To calculate generalization scores for each participant for nasal coda duration, I ran linear one linear model per participant of the form duration[ND]~condition[ND]+(1|word[ND]). %The code for how I calculated generalization scores (t values) was as follows, using subject15 as an example: SMdf$AN_gene[SMdf$speaker=="subject15"]<-coef(summary(lmer(ANdf$duration[ANdf$filename=="subject15"&ANdf$dialect=="ND"]~relevel(ANdf$condition[ANdf$filename=="subject15"&ANdf$dialect=="ND"], ref="pretest")+(1|ANdf$word[ANdf$filename=="subject15"&ANdf$dialect=="ND"]), REML = F)))[6]
The models were non-REML. The generalization score was just the t value that the model spat out for the predictor variable (condition). For some of the participants (1,5,7,10,11,14 at time of writing (cuz I only have data for 15 people at the moment)), R refused to make a linear model cuz there was literally no change from pretest to posttest, they just always had no coda for every single word in ND in both the pre- and posttest blocks. R would throw the following error:

\begin{quote}
Error in asMethod(object) : not a positive definite matrix

In addition: Warning message:

In vcov.merMod(object, use.hessian = use.hessian) :

Computed variance-covariance matrix problem: not a positive definite matrix;

returning NA matrix
\end{quote}
Because it wouldn't calculate a t value for me in these cases, I set the generalization score to 0 for these people. That \textit{may} not really be super reasonable, but I think it's okay (no I don't). The t value is the how much change the model predicts, divided by how variable the data is. If the model manages to predict a relatively large change between conditions relative to how variable the data are, then you get a big t value, and you can be fairly sure that ...supposed to be how consistently they changed their behavior in whatever direction, then really a t value of 0 means that their behavior should be totally unpredictable (this is borne out by tests I ran using "t value test.csv"). What's actually going on with the people who are just always 0 is that they are PERFECTLY predictable, there's no variation, and so you're dividing by 0. No good.

\hl{There's graph on my WSC5 poster (hypothesis 4) that belongs in here somewhere}.

\section{Results}
\label{sec:externalResults}
For each (linguistic) variable, a single model was created that predicted Baseline ND inter-personal Mandarinization from history, use, proficiency, explicit attitudes, IAT score, and VOT imitation score. 

\section{Shadowing DiD predicts posttest DiD}
This is important cuz it's like the central point of the dissertation, I think. It's at least the central point of my LSA 2019 abstract. The more an individual changed towards the model on a given word during the shadowing block, the more likely they were to be closer to the model during the posttest, too. That (maybe?) says imitators hold on to dialect features across interactional contexts better than non-imitators... Either that, or that some words are more susceptible to being imitated AND carried across dialects. (I think it's kind of a flaw in the methodology that DiD is only looking at speaker-word instances across conditions.)

%For two dialects to affect each other, their speakers must be in contact, and at least one set of speakers must adopt their interlocutors' speech features, take those features home, and start showing them off to their friends and family. This scenario, of course, assumes that dialects can directly affect each other, and that instances of things like Andean Spanish developing ejective consonants are, in fact, caused by contact with ejective-having languages like Quechua, rather than having occurred by chance.

\hl{Why is NAS hyper-significant in both the post-test and the Mandarinization prediction models? Is it cuz there's 5 times as many data points?}

Maybe; if I subset the tokengn data so that it's only looking at tp3, the significant codes go to use (**), explicit (*), IAT(.), and gender (.)., totaling 3.2 stars instead of the 14.1 it had without subsetting. That reduction is less marked, though, in the Mandarinization model, where we get use (***), proficiency (*), explicit (.), gender (***), and education (**) totaling 9.1 after switching to the midpoint, instead of 14 for all 5 timepoints.

\hl{Which factors are significant for a given ling variable in both generalization and mandarinization?}

Proficiency predicts VOT in both

Use predicts NAS in both

IAT predicts IY in both

Nothing predicts IE in both

History and age predict LN in both

\hl{Which ling variables are predicted by a given factor in both?}

History predicts LN in both

use predicts NAS in both

Proficiency predicts VOT in both

Explicit doesn't predict anything in both

IAT predicts IY in both

Imitation doesn't predict anything in both

Age predicts LN in both

Gender doesn't predict anything in both

Education doesn't predict anything in both

Use predicts NAS in both

\hl{Why is VOT hyper-significant in the Mandarinization prediction model?}

This makes no sense to me. Originally at least, I'd have expected VOT to be relatively well predicted in generalization and poorly predicted in Mandarinization, because it was supposed to be a novel variable that didn't actually differ in \emph{any} predictable way in the wild, only being affected by my manipulation. Instead, it's the 3rd most predictable (by number of stars; 5, 3.2, \emph{3}) for generalization and the \emph{most} predictable \emph{by far} (\emph{18}, 9.1, 7.1) for Mandarinization. I \emph{think} the hyper-significance for Mandarinization means that not only is VOT different between the dialects, but that it might be like a pretty reliable indicator of Mandarinization in general... But why would that be? Maybe just cuz VOT is an important acoustic dimension which people use to maintain a phonological contrast (between /p/ and /p\textsuperscript{h}/ in both dialects), and a social contrast(...apparently) between Mandarin and Nanjing Dialect. Maybe it's just less messily measured? Like, maybe my VOT interval alignments are closer to speakers' psychological realities than my LPC formant measures? I \emph{do} feel like I can make better\slash more consistent VOT measurements than I can formant measurements, though that's just a feeling. Maybe that's something worth investigating... the effect of the accuracy of these types of measurements on statistical analyses. Like, intentionally add jitter to VOT measures and compare the stats that come out to non jittery ones, and extend the analysis to formants or other acoustic measures... somehow.

For lack of a more sophisticated statistical method, I assess the degree of significance of a predictor (or set of predictors) by counting the number of stars in the significance code provided by R's \citep{r2013r} anova function. Essentially this is a shorthand for the \textit{p}-value of the likelihood ratio test that excludes that particular predictor. Values between $0$ and $0.001$ get three stars, values between $0.001$ and $0.01$ get two stars, between $0.01$ and $0.05$ get one, and values between $0.05$ and $0.1$ get a period. Periods, I've decided, are worth 0.1 stars. I understand that generally, one is meant to simply decide on an acceptable $\alpha$ level and state whether results are ``significant'' or ``insignificant,'' rather than trying to describe \emph{how} significant something is, but it's also my understanding that a \textit{p}-value is essentially a measure of how likely you are to be wrong if you decide to reject the null hypothesis. So, if your \textit{p}-value is $0.001$, you're less likely to be wrong than if your \textit{p}-value is $0.002$, even though they would both just be ``significant'' at $\alpha = 0.05$. I therefore feel justified asserting that a three-star predictor is a better (i.e. surer) predictor than is a two-star one.

%``by totalling all stars in the generalization models---12.3---and comparing to the total number in the Mandarinization models---39.4---I can claim that ``Mandarinization is better predicted than generalization by the set of independent variables used here.''
By totalling the full and fractional stars across, for example, all of the ``history'' predictors for each linguistic variable in the Mandarinization prediction models---there are 5---and then comparing that to the number of stars for, say, proficiency in the same set of models---there are 7---I can claim that ``history is a poorer predictor of Manadarinization than is proficiency.'' Or, by totalling all stars in the generalization models---12.3---and comparing that to the total number in the Mandarinization models---39.4---I can claim that ``Mandarinization is better predicted than generalization by the set of independent variables used here.'' I apply this logic both within and across linguistic, independent, and dependent variables.

\hl{What does the total number of stars in each table mean? What does the number of stars per column mean? The number of stars per row? The specific combination of stars that are there?}

\hl{Do the Mandarinization prediction estimates go the way you'd expect?} For the dominance measures, it's not always super clear what their relationship to Mandarinization \emph{should} be. You'd think that higher scores---indicating greater Nanjing Dialect dominance---should always predict less Mandarinization, but mostly they predict \emph{more}, the only exception being VOT.Proficiency., but the fact that Proficiency predicts less Mandarinization for NAS and IY but more for VOT kind of throws a bit of a monkey wrench in there.

.History makes no sense; basically, the earlier you started learning Nanjing Dialect\slash later you started learning Mandarin, the \emph{less} difference there is between your Nanjing Dialect and Mandarin VOT baselines. Maybe cuz you just acquired a ND-y VOT and kept it? But there's no difference between Nanjing Dialect baseline VOTs attributable to History, according to a linear model.\footnote{duration $\sim$ history $+$ (1 $|$ speaker)}

NAS.Use makes sense, cuz it says that using Nanjing Dialect more predicts less Mandarinization. Proficiency makes sense for NAS and IY, for the same reason, but is also therefore confusing in the VOT model. Why does greater 

\hl{...I just haven't quite figured out what to think about all these estimates...}