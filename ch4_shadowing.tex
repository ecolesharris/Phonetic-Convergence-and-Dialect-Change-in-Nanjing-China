\chapter{Experiment-internal Accommodation}
\label{internalchapter}

\section{Introduction}
\label{sec:shadowingIntro}
The big conceptual question that I'm beginning to address here is: ``Is interpersonal accommodation really what drives dialect change in a contact situation?'' In this chapter, I'll be answering that question from an experiment-internal perspective. In other words, I'll be describing the link between participant shadowing and generalization, both in terms of how the group behaves and how individuals behave. I'll be describing my attempt to recreate the dynamic that Trudgill \citeyearpar{trudgill1986dialects} describes (i.e., first accommodating to an interlocutor (short-term accommodation), and then continuing to use the accommodated-to features after the interlocutor isn't there anymore (long-term accommodation).

This chapter is more or less about whether there was any change going on within the context of the experiment.

\section{Hypotheses Tested}
I'll say these again when I get to the specific bits of the experiment that address them. These hypotheses are testing an extreme version of the idea that change is ``mechanistic'' that assumes that any exposure to weird PTH will just automatically translate to the same thing showing up in ND.

\begin{enumerate}
    \item The model's VOT will be different from (longer than) the participants' PTH VOT;
    \item The model's nasal coda presence will be different from (more present than) the participants' PTH nasal coda presence;
    \item The group as a whole will significantly change (lengthen) their VOT when they shadow;
    \item The group as a whole will significantly change (increase) nasal coda presence when they shadow;
    \item The group as a whole will significantly change (lengthen) their VOT in the ND post-test;
    \item The group as a whole will significantly change (increase) nasal coda presence in the ND post-test;
    \item The group as a whole will not significantly change their degree of diphthongization (\textipa{[e]/[iE]}) in the ND post-test;
    \item The group as a whole will not significantly change their F2 ([l]/[n]) in the ND post-test;
    \item The group as a whole will not significantly change their F3 ([i]/[y]) in the ND post-test.
\end{enumerate}

\section{Group Behavior}
\label{sec:expint:group}

People behaved \textit{way X} as a group. This has \textit{theoretical significance Y}.

\subsection{hypotheses}
stuff

\subsection{Results}
\label{sec:expint:group:results}
 The mean model VOT is longer than the mean participant baseline PTH VOT (see section \ref{ssec:baselines:model}) and the \hl{peak nasality} is later (\hl{I haven't actually done this math}), and so the participants are expected to lengthen their VOT and delay the peak of their nasality when shadowing the model recording. %I *think* this works, but I should verify this and make sure the math isn't crazy… like, unequal variances are a thing… so…

%The first part of this worked out great; as a group,...
For VOT, participants behaved as expected. Overall, they significantly lengthened their VOTs when they were listening to the shadowing recordings, %, with the overall change in VOT during shadowing was...
which is the direction in which we'd expect change to take place (towards the model's extended VOT). A likelihood ratio test\footnote{anova(VOT.PTH.condition.lmer, VOT.PTH.condition.null), AIC$_{null}$ = -13906, AIC$_{full}$ = -13984}confirmed that the data was \hl{XXXXX} times as likely under a linear mixed effects regression predicting participant PTH VOTs by experimental condition (pre-test vs. shadowing) with random effects for speaker and word\footnote{Duration $\sim$ Condition + ( 1 $|$ Speaker ) + ( 1 $|$ Word ), data = Mandarin VOTs.}than under a null model (excluding the condition predictor); $\chi^2 (1) = 79.687$, $p < 2.2e-16$. The better-fitting model gives an estimate of $+6.3289$ ms $\pm 0.7036$ (std. errors) from the pre-test condition (M = 93 ms) to the shadowing condition (M = 99 ms). 

\hl{This whole paragraph probably needs to be revised, cuz it's about A1-P0 throughout the vowel, rather than being about where the peak is.} Nasality is different. While impressionistic judgments of the presence of nasal codas were significantly different between the dialects (see chapter \ref{baselinechapter}\hl{(I haven't actually written this into the baseline chapter yet.)}) and a generalized linear mixed effects model indicated a significant difference in nasal coda presence between the Mandarin pre-test and shadowing blocks (41.5\% and 55.4\% present, respectively; \hl{I don't actually know how to interpret or report the glmer results, but $p < 2e-16$ according to \textbf{AN.PTH.condition.glmer}}), there is no overall change with respect to A1-P0 from the pre-test to the shadowing conditions. I performed two likelihood ratio tests: one between
\begin{itemize}
    \item a linear mixed effects regression predicting participant PTH A1-P0s by experimental condition (pre-test vs. shadowing), measurement timepoint within the word (1-5), and the interaction between these two predictors with random effects for speaker and word,\footnote{A1-P0 $\sim$ Condition * Timepoint + ( 1 $|$ Speaker ) + ( 1 $|$ Word ). %I'm not sure what to do about the timepoint thing. I don't know if it's better to include it or deliberately leave it out
    }and
    \item a null model excluding the interaction\footnote{A1-P0 $\sim$ Condition + Timepoint + ( 1 $|$ Speaker ) + ( 1 $|$ Word ).}
\end{itemize}
with the result $\chi^2(1) = 1.1143$, $p = 0.2912$, and another between
  \begin{itemize}
    \item the interactionless model and
    \item a null model excluding the condition predictor \footnote{A1-P0 $\sim$ Timepoint + ( 1 $|$ Speaker ) + ( 1 $|$ Word ).}.
\end{itemize}
with the result $\chi^2(1) = 1.0648$, $p = 0.3021$.
These likelihood ratio tests both failed to reject the null hypothesis that the models were not significantly different, and so I conclude that neither experimental condition nor the interaction between condition and timepoint have any effect on Mandarin A1-P0. Practically, this means that there was no difference in the overall nasality of participant vowels across conditions, nor between the nasality of the vowel at a given timepoint across conditions (i.e., the locus of their nasality didn't shift to a different point in the vowel). These results are both contrary to expectations, given that greater presence of nasal codas in the shadowing condition should shift the nasality out of the vowel and into the coda, reducing both overall nasality and nasality early in the vowel specifically. The fact that neither of these things happened even though I judged there to be significantly more codas in the shadowing condition suggests that participants may have imitated presence of the oral gesture without imitating the timing of the nasal gesture.

\hl{I should give the shadowing stuff context here and then transition into the post-test stuff.}

In the post-test bit, I wanted to measure how much people's Nanjing Dialect changed after exposure to Mandarin. I'm measuring several different pre-test-to-post-test changes in Nanjing Dialect pronunciation here:
\begin{enumerate}
    \item duration of VOT (``extended [p\super{h}] words''),
    \item value of A1-P0 at 5 points throughout the vowel (nasality, [\~{\ae}]/[{\ae n}] words),
    \item F1-F2 formant trajectory along 4 segments of the vowel, which I generally refer to as ``degree of diphthongization,''( \textipa{[e]/[iE]} words),
    \item F3 value at the midpoint of the vowel (``\textipa{[I]/[y]} words''), and
    \item F2 value at the midpoint of the consonant (``\textipa{[l]/[n]} words'').
\end{enumerate}

VOT did not change for the group as a whole; $\chi^2(1) = 1.2861$, $p = 0.2568$. This is based on the same type of likelihood ratio test as described for VOT in section \ref{sec:expint:group:results} above, but for Nanjing Dialect between the pre- and post-test conditions instead of Mandarin between the pre-test and shadowing conditions. It's not exactly \textit{surprising} that there was no change, but this is \textit{different} from the Mandarin pre-test to shadowing comparison, which showed a significant change between conditions. One might have expected that, because the group shadowed significantly, they would also generalize significantly. This does not turn out to be the case.

A1-P0 did change between the pre- and post-test conditions. A likelihood ratio test\footnote{anova(NAS.ND.condition.lmer, NAS.ND.condition.null), AIC$_{null}$ = 55644, AIC$_{full}$ = 55636}confirmed that the data was \hl{XXXXX} times as likely under a linear mixed effects regression predicting participant Nanjing Dialect A1-P0s by experimental condition (pre-test vs. post-test) \hl{and timepoint (1-5)} with random effects for speaker and word\footnote{A1-P0 $\sim$ Condition + Timepoint + ( 1 $|$ Speaker ) + ( 1 $|$ Word ), data = Nanjing Dialect A1-P0s.}than under a null model (excluding the condition predictor); $\chi^2 (1) = 9.8995$, $p = 0.001653$. The better-fitting model gives an estimate of $+0.3571$ dB $\pm 0.1135$ (std. errors) from the pre-test condition (M = -3.83 dB) to the post-test condition (M = -3.47 dB), which we're taking to mean an overall reduction in nasality in the vowel. This is the direction of change we'd expect to be associated with greater presence of nasal codas, but is surprising given the fact that there was no significant change in Mandarin A1-P0 from the pre-test to the shadowing conditions. A separate likelihood ratio test ($\chi^2(1)=1.1143$, $p=0.2912$) between a model including an interaction between condition and timepoint failed to reject the null hypothesis that condition has no effect on the A1-P0 values of particular timepoints, meaning that there was no difference in the overall shape of the A1-P0 curve, just that it shifted upward between the experimental conditions.

\textipa{[e]/[iE]} did not change for the group as a whole; $\chi^2(1) = 0.0295$, $p = 0.8636$. This is based on the same type of likelihood ratio test as described for VOT in section \ref{sec:expint:group:results} above, but for Nanjing Dialect between the pre- and post-test conditions instead of Mandarin between the pre-test and shadowing conditions, and for \textipa{[e]/[iE]} measures instead of VOT measures. \hl{It's hard to say what the likeliest prediction here should have been}. I know that when I started thinking about this I was kind of hoping that the other variables (``\textipa{[e]/[iE]},'' ``\textipa{[I]/[y]},'' and ``\textipa{[l]/[n]}'') would show a consistent change in the Mandarin direction, but I don't know if that would have actually been a reasonable \textit{prediction}.

\textipa{[I]/[y]} did not change for the group as a whole; $\chi^2(1) = 0.0072$, $p = 0.9322$. This is based on the same type of likelihood ratio test as described for VOT in section \ref{sec:expint:group:results} above, but for Nanjing Dialect between the pre- and post-test conditions instead of Mandarin between the pre-test and shadowing conditions, and for \textipa{[I]/[y]} measures instead of VOT measures.

Participant behavior in the \textipa{[l]/[n]} words \textit{did} change for the group as a whole between the pre-test and the post-test, even though there was no initial difference between the two dialects in the pre-test condition and no exposure to manipulated versions of this particular feature. A likelihood ratio test\footnote{anova(LN.ND.condition.lmer, LN.ND.condition.null), AIC$_{null}$ = 26568, AIC$_{full}$ = 26559}confirmed that the data was \hl{XXXXX} times as likely under a linear mixed effects regression predicting participant Nanjing Dialect F2s by experimental condition (pre-test vs. post-test) with random effects for speaker and word\footnote{F2 $\sim$ Condition + ( 1 $|$ Speaker ) + ( 1 $|$ Word ).}than under a null model (excluding the condition predictor); $\chi^2 (1) = 10.993$, $p = 0.0009146$. The better-fitting model gives an estimate of $+76.05\textrm{ Hz } \pm 22.90$ (std. errors) from the pre-test condition (\hl{M = 1762 Hz}) to the post-test condition (\hl{M = 1825 Hz}). This is what we would expect given that the post-test should, at least ideally, be more Mandarin-y than the pre-test, meaning having fewer instances of ``l'' sounding things than the less Mandarin-y pre-test. It is odd, however, because my impressionistic labels say that there are \textit{more} ``l'' sounding things in the post-test, not fewer. \hl{Are my ears bad? Are my measures bad? Am I just measuring the wrong thing? I think my ears are bad.}

\subsection{Individual Behavior}
\hl{Shadowing things for individuals (meaning predictions of behavior, I guess?) go here.} Shadowing behavior at the individual level was predicted \hl{for both VOT and A1-P0} from the following variables:

\begin{enumerate}
    \item token-by-token shadowing behavior (DiD),
    \item age,
    \item gender,
    \item the district of Nanjing that participants felt their Nanjing Dialect belonged to,
    \item current district of residence within the city,
    \item education level,
    \item history,
    \item use,
    \item proficiency,
    \item explicit attitudes,
    \item IAT score,
    \item token-by-token Nanjing Dialect baseline \hl{VOT} duration (\hl{even for NAS? Maybe it makes sense if you're just taking it as a proxy for overall Mandarinization, but I don't think that's a good idea. Or did I do separate baseline measures for VOT and for NAS?}),
    \item token-by-token Mandarin baseline \hl{VOT} duration, and
    \item VOT imitation score.
\end{enumerate}
All variables were scaled so they wouldn't be like on the order of .0001 for some and 1000 for others. A single full model was compared to 14 null models--each leaving out one of the above variables--11 likelihood ratio tests. \hl{I imagine this requires alpha-level adjustment; double-check this with someone who understands stats.} The results are listed in tables \ref{tab:VOTpostPredictors} and \ref{tab:NASpostPredictors} \hl{below}. \hl{The tables are incomplete and/or out of order.}

\begin{table}
\centering
 \begin{tabular}{|c||c|c|c|c|c|c|} 
 \hline
 \textbf{Variable removed} & \textbf{AIC$_{full}$} & \textbf{AIC$_{null}$} & $\chi^2$ & \textbf{DF} & \textbf{$p$-value} & \textbf{Significance}\\ [0.5ex] 
 \hline
  Shadowing & -4100.0 & -4094.3 & 7.7586 & 1 & $0.005346$ & **\\ 
 \hline
 Age & -4100 & -4102 & 0.0314 & 1 & $0.8594$ & \\
 \hline
 Gender & -4100.0 & -4098.5 & 3.5089 & 1 & $0.06104$ & \\
 \hline
 District & -4100.0 & -4089.4 & 22.6 & 6 & $0.000942$ & ***\\
 \hline
 Residence & -4100.0 & -4075.7 & 34.321 & 5 & $2.055e-06$ & ***\\
 \hline
 Ednum & -4100.0 & -4103.2 & 4.796 & \hl{4} & $0.3089$ & \\
 \hline
 History & -4100.0 & -4101.3 & 0.7293 & 1 & $0.3931$ & \\
 \hline
 Use & -4100.0 & -4101.6 & 0.4573 & 1 & $0.4989$ & \\
 \hline
 Proficiency & -4100.0 & -4101.4 & 0.6756 & 1 & $0.4111$ & \\
 \hline
 Explicit & -4100.0 & 4100.8 & 1.2905 & 1 & $0.256$ & \\
 \hline
 IAT score & -4100 & -4102 & 0.0683 & 1 & $0.7938$ & \\
 \hline
 ND Baseline & -4100.0 & -3952.7 & 149.3 & 1 & $< 2.2e-16$ & ***\\
 \hline
 PTH Baseline & -4100.0 & -4082.3 & 19.753 & 1 & $8.812e-06$ & ***\\
 \hline
 \hl{Imitation} & -4100 & -4080 & 22.006 & 1 & $2.718e-06$ & ***\\%this is going to be strongly correlated with shadowing
 \hline
\end{tabular}
\caption{VOT post-test generalization (DiD) prediction. \hl{I think the numbers here are okay.}}
\label{tab:VOTshadPredictors}
\end{table}

\begin{table}
\centering
 \begin{tabular}{|c||c|c|c|c|c|c|} 
 \hline
 \textbf{Variable removed} & \textbf{AIC$_{full}$} & \textbf{AIC$_{null}$} & $\chi^2$ & \textbf{DF} & \textbf{$p$-value} & \textbf{Significance}\\ [0.5ex] 
 \hline
  Shadowing & -4100.0 & -4094.3 & 7.7586 & 1 & $0.005346$ & **\\ 
 \hline
 Age & -4100 & -4102 & 0.0314 & 1 & $0.8594$ & \\
 \hline
 Gender & -4100.0 & -4098.5 & 3.5089 & 1 & $0.06104$ & \\
 \hline
 District & -4100.0 & -4089.4 & 22.6 & 6 & $0.000942$ & ***\\
 \hline
 Residence & -4100.0 & -4075.7 & 34.321 & 5 & $2.055e-06$ & ***\\
 \hline
 Ednum & -4100.0 & -4103.2 & 4.796 & \hl{4} & $0.3089$ & \\
 \hline
 History & -4100.0 & -4101.3 & 0.7293 & 1 & $0.3931$ & \\
 \hline
 Use & -4100.0 & -4101.6 & 0.4573 & 1 & $0.4989$ & \\
 \hline
 Proficiency & -4100.0 & -4101.4 & 0.6756 & 1 & $0.4111$ & \\
 \hline
 Explicit & -4100.0 & 4100.8 & 1.2905 & 1 & $0.256$ & \\
 \hline
 IAT score & -4100 & -4102 & 0.0683 & 1 & $0.7938$ & \\
 \hline
 ND Baseline & -4100.0 & -3952.7 & 149.3 & 1 & $< 2.2e-16$ & ***\\
 \hline
 PTH Baseline & -4100.0 & -4082.3 & 19.753 & 1 & $8.812e-06$ & ***\\
 \hline
 \hl{Imitation} & -4100 & -4080 & 22.006 & 1 & $2.718e-06$ & ***\\%this is going to be strongly correlated with shadowing
 \hline
\end{tabular}
\caption{VOT post-test generalization (DiD) prediction. \hl{I think the numbers here are okay.}}
\label{tab:VOTpostPredictors}
\end{table}

\begin{table}
\centering
 \begin{tabular}{|c||c|c|c|c|c|c|} 
 \hline
 \textbf{Variable removed} & \textbf{AIC$_{full}$} & \textbf{AIC$_{null}$} & $\chi^2$ & \textbf{DF} & \textbf{$p$-value} & \textbf{Significance}\\ [0.5ex] 
 \hline
  Shadowing & \hl{XXXXX} & \hl{XXXXX} & 3.3421 & 1 & $0.06753$ & \\ 
 \hline
 Age & \hl{XXXXX} & \hl{XXXXX} & 4.6671 & 1 & $0.03075$ & *\\
 \hline
 Gender & \hl{XXXXX} & \hl{XXXXX} & 1.8856 & 1 & $0.1697$ & \\
 \hline
 District & \hl{XXXXX} & \hl{XXXXX} & 14.657 & 6 & $0.0231$ & *\\
 \hline
 Residence & \hl{XXXXX} & \hl{XXXXX} & 10.474 & 5 & $0.06287$ & \\
 \hline
 Education & \hl{XXXXX} & \hl{XXXXX} & 1.3071 & 1 & $0.2529$ & \\
 \hline
 \hl{Dominance} & \hl{XXXXX} & \hl{XXXXX} & 5.003 & 1 & $0.0253$ & *\\%this probably needs to be broken apart.
 \hline
 IAT score & \hl{XXXXX} & \hl{XXXXX} & 0.2535 & 1 & $0.6146$ & \\
 \hline
 ND Baseline & \hl{XXXXX} & \hl{XXXXX} & 0.024 & 1 & $0.8769$ & \\
 \hline
 PTH Baseline & \hl{XXXXX} & \hl{XXXXX} & 0.0396 & 1 & $0.8422$ & \\
 \hline
 \hl{Imitation} & \hl{XXXXX} & \hl{XXXXX} & 0.1262 & 1 & $0.7224$ & \\%this is going to be strongly correlated with shadowing... right?
 \hline
\end{tabular}
\caption{\hl{This whole table is problematic.} A1-P0 shadowing prediction. \hl{I can't do DiD prediction models for A1-P0 cuz person-to-person comparison AND I just don't have Annie's A1-P0 yet.}}
\label{tab:NASshadPredictors}
\end{table}

Here are the estimates for the significant predictors:
\begin{table}
\centering
 \begin{tabular}{|c||c|c|c|} 
 \hline
 \textbf{Variable} & \textbf{Estimate (seconds)} & \textbf{Standard Err.} & \textbf{t value}\\ [0.5ex] 
 \hline
  (Intercept) & 9.339e-03 & 2.306e-02 & 0.405\\ 
 \hline
  Shadowing & 1.391e-01 & 4.876e-02 & 2.854\\ 
 \hline
 District:Baixia (Reference) & \hl{???} & \hl{???} & \hl{???}\\
 \hline
 District:Dachang & $-1.328e-02$ & $1.536e-02$ & $-0.865$\\
 \hline
 District:Gulou & $1.693e-03$ & $5.130e-03$ & $0.330$\\
 \hline
 District:Jiangning & $3.183e-02$ & $7.920e-03$ & $4.019$\\
 \hline
 District:Jianye & $3.368e-03$ & $6.814e-03$ & $0.494$\\
 \hline
 District:Qinhuai & $2.078e-02$ & $4.639e-03$ & $4.479$\\
 \hline
 District:Xuanwu & $7.931e-03$ & $4.293e-03$ & $1.847$\\
 \hline
 Residence:Gulou (Reference) & \hl{???} & \hl{???} & \hl{???}\\
 \hline
  Residence:Jiangning & $-3.460e-02$ & $9.678e-03$ & $-3.576$\\
 \hline
  Residence:Jianye & $-4.248e-03$ & $4.738e-03$ & $-0.897$\\
 \hline
  Residence:Qinhuai & $-2.892e-02$ & $6.915e-03$ & $-4.181$\\
 \hline
  Residence:Qixia & $-1.109e-02$ & $6.046e-03$ & $-1.834$\\
 \hline
  Residence:Xuanwu & $-4.479e-03$ & $7.226e-03$ & $-0.620$\\
 \hline
 ND Baseline & $-3.800e-01$ & $2.841e-02$ & $-13.376$\\
 \hline%phonetic space
 PTH Baseline & $2.349e-01$ & $4.962e-02$ & $4.734$\\
 \hline
 \hl{Imitation} & $-1.613e-03$ & $3.286e-04$ & $-4.909$\\%this is going to be strongly correlated with shadowing
 \hline
\end{tabular}
\caption{Significant VOT post-test generalization (DiD) prediction estimates, etc.}
\label{tab:VOTpostEstimates}
\end{table}

This set of estimates mean (narrowly) that:
\begin{itemize}
    \item People who shadowed the model more closely on an acoustic, token-by-token basis were more likely to shift their post-test pronunciation towards the shadowing model (i.e., ``generalize'') for VOT.
    \item People whose home districts within the city are Jiangning or Qinhuai were more likely to generalize (than those who come from Baixia).
    \item People currently living in Jiangning or Qinhuai were more likely to generalize (than those who currently live in Gulou).
    \item Those with longer (more Mandarin-like) VOTs in their Nanjing Dialect baseline were less likely to generalize (\hl{which jibes with the ``phonetic space'' explanation}).
    \item Those with longer (more Mandarin-like) VOTs in their Mandarin baseline were more likely to generalize. (\hl{I'm not sure what's going on here. The fact that their Mandarin baseline says ANYTHING about their ND post-test seems like it must be a pretty strong indication that the dialects influence each other, but maybe that's like a byproduct of the bidialectalism in Nanjing? Where like because interaction occurs in Mandarin, the change has to take place in Mandarin first, and then spreads through the system to Nanjing Dialect?}) %It would be good to do a set of similar-- though simpler and more focused--experiments where I try to see if the reason these things look weird is a) the language of interaction, b) cuz my participants were all bidialectal.
    \item The more consistently people lengthened their VOT, the \textit{less} they lengthened their post-test ND. \hl{This is also super hard for me to explain, because their imitation score is \textit{negatively} correlated with their post-test DiD, but their shadowing DiD is \textit{positively} correlated with it! They're basically the same measure, but they point in opposite directions! I think probably what this means is that I should not use imitation score.}% summary(lm(did~imitation,data=subset(VOTdf,block=="3"))) tells me (I think) that imitation score and shadowing are positively correlated 
\end{itemize}
    
\subsection{Discussion}

The results above indicate that:
\begin{enumerate}
    \item participant baseline PTH VOTs were significantly shorter than the model's artificially extended VOTs (i.e., there was room for them to shadow VOT), \hl{and participant baseline PTH nasal peaks were significantly earlier than the model's as well};
    \item participants displayed an overall shift towards longer Mandarin VOTs and more present nasal codas when shadowing the manipulated model token (i.e., they shadowed), but didn't display an overall shift in their Nanjing Dialect VOTs or nasal codas in the post-test (i.e., they didn't seem to ``generalize'' the change we saw in the shadowing block); and
    %\item participants did \textit{not} display an overall shift of any sort in their Mandarin A1-P0s when shadowing (i.e., they prolly didn't shadow nasality \hl{tho I'm not sure, cuz I haven't measured Annie's A1-P0})but \textit{did} change their Nanjing Dialect A1-P0 from the pre-test to the post-test blocks, which is the opposite of VOT; and
    \item participants did not change their behavior from pre- to post-test for \textipa{[e]/[iE]} or \textipa{[I]/[y]}, but \textit{did} for \textipa{[l]/[n]}, despite not having exposed to a shadowing model for any of these last three variables (i.e., the non-shadowed variables behave inconsistently).
    \item \hl{there's a commented-out item above}.
\end{enumerate}
The group-level shift towards the model's extended VOTs during shadowing is what we'd expect, cuz we know that people imitate fine phonetic detail in situations like these (\hl{CITATIONS}), and they had plenty of room to imitate given the ridiculously long model VOTs. The lack of generalization isn't necessarily surprising, because no one has established empirically that that's how things work, and even if that \textit{is} how things work, it's possible that exposure to my edited VOTs was too brief or that the VOTs themselves were too outlandish to inspire generalization.

However, the NAS results aren't exactly what I would have predicted. Because of the difference in impressionistic nasal coda presence percepts for the Mandarin pre-test vs. shadowing data, I would have expected that A1-P0 would be different in the shadowing condition, probably by being higher until later in the word. I guess I'm not sure how I would expect that to show up in the model's results, but I would have thought there'd be a difference when excluding condition. I also tried a model without condition and a model with an interaction between condition and timepoint, but all were insignificantly different from null models. Also, for WSC5 I did a thing that I probably shouldn't; specifically, I did a DiD lmer, which is problematic with nasality, cuz it's doing a direct inter-speaker comparison of the acoustics, which is apparently a no-no. I'm gonna pretend I don't know that for the time being. This is perhaps why I should switch to the nasality curve timing thing. 

So here are the questions raised by these facts:

\begin{enumerate}
    \item why do you get shadowing of VOT, but (probably) not A1-P0?
    \item why do you get what looks like generalization for A1-P0, but not for VOT, especially given the shadowing pattern mentioned \hl{above}.
    \item \hl{why should there be an overall decrease in nasality in the post-test [\~\ae]/[\ae n] vowels if not because of a rightward shift in the locus of nasality?}
\end{enumerate} \hl{I don't have a good answer for this yet}.

The variables that didn't get shadowed (\textipa{[e]/[iE]}, \textipa{[I]/[y]}, \textipa{[l]/[n]}) are kind of hard to interpret as well. In my ideal imaginary dissertation, they all would have become more Mandarinized in the post-test, which would have made it easy to be like ``Look! Interaction in Mandarin causes Nanjing Dialect to Mandarinize,''  but instead only one of the three showed that overall pattern, and the other two showed no change at all. The best explanation I can come up with for that at this point is that Nanjing Dialect speakers are (at least anecdotally) explicitly aware of the \textipa{[l]/[n]} thing in their dialect, but not \textipa{[e]/[iE]} or \textipa{[I]/[y]} (at least not on the same level), and so maybe they were being extra careful in the Mandarin pre-test, which then carried over into the Nanjing Dialect post-test. This explanation is insufficient on its own, though, because it can't explain why there's pre- post- difference in A1-P0 for Nanjing Dialect; I'm pretty sure that no one knows they're doing the ``missing nasal coda'' thing.

\pagebreak

This page intentionally left blank.

\pagebreak

Their Nanjing Dialect, however, didn't change between the pre- and post-test conditions when considered as a group.
\footnote{Changes to ND pronunciation from ``pre-test'' to ``post-test'' condition; i.e., did they generalize as a group?:

VOT: duration $\sim$ condition + ( 1 $|$ speaker ) + ( 1 $|$ word ), data = Mandarin VOTs

Nasality: A1-P0 $\sim$ condition + ( 1 $|$ speaker ) + ( 1 $|$ word ), data = Mandarin A1-P0s

\textipa{[e]/[iE]}: diphthongization $\sim$ condition + ( 1 $|$ speaker ) + ( 1 $|$ word ), data = Nanjing Dialect diphthongization measures

\textipa{[i]/[y]}: F3 $\sim$ condition + ( 1 $|$ speaker ) + ( 1 $|$ word ), data = Nanjing Dialect F3s

\textipa{[l]/[n]}: F2 $\sim$ condition + ( 1 $|$ speaker ) + ( 1 $|$ word ), data = Nanjing Dialect F2s

}

Each of these models was subjected to a likelihood ratio test (anova) comparing the full model (above) with a null model that ommitted the fixed effect term (+ condition). The results were as follows:

VOT:

$\chi^2(1) = 79.687$, $p < 2.2e-16$, while $AIC_{full} = -13984$ whereas $AIC_{null} = -13906$

So the models are significantly different, and the full model describes the data better (has a lower AIC). That means we can take what the full model says about the data seriously.

The full model says that overall, we see a 6 ms increase in subject VOTs from the pre-test condition (mean: 83 ms) to the shadowing condition (mean: 89 ms). \hl{It probably says more that that, but that's what I know how to interpret at the moment.}

The second bit didn't work exactly like I thought it would, because there was not a statistically significant group-wide change in participants' Nanjing Dialect \textit{after} the shadowing bit. Overall, exposure to Mandarin within the context of the experiment did not engender lasting effects in the Nanjing Dialect of the group.

\section{Individual Behavior}
\label{sec:expint:individual}
\subsection{shadowing}
\subsection{post-test}
However, there were some individuals (n = 7) who changed pretty consistently in the , but not all in the direction that Trudgill's theory would have suggested given the way that they accommodated during the shadowing portion of the experiment (that is to say, towards the model), nor all in the direction that prior research on the persistence of shadowing might predict \citep{pinget2015actuation}. Of the seven whose behavior changed consistently (i.e., the absolute value of a t-value for a linear model predicting the individual's Nanjing Dialect VOT duration by experimental condition was greater than 2), only three lengthened their VOTs in the post-test \hl{(which I think of as Trudgill-style, though I'm not actually 100\% sure that Trudgill ever says ``more imitation = more dialect change'')}, while the other four shortened them. On top of that, of the three who lengthened, only two had consistently lengthened their VOT in the shadowing portion of the experiment, while the other did not make consistent changes to VOT during the shadowing block at all. Similarly, of the four who shortened their VOTs in the post-test, three had lengthened their VOTs in the shadowing block \hl{(as Pinget might predict)}, and one made no consistent changes. A linear model predicting an individual's \hl{VOT generalization score} from their \hl{VOT imitation score} was also not significant ($p = 0.427$).%I don't actually really know what I mean here. I think I'm saying that I ran this model: anova(lm(SMdf$VOT_gene~SMdf$VOT_imit),lm(SMdf$VOT_gene~1)) and it said that VOT generalization is not well predicted by VOT imitation, but that's also only on the level of the imitation/generalization *scores*, which are already pretty far removed from the data... but I can't really do a token-by-token version of this, I don't think, without resorting effectively to DiD.
This is like the simplest and most direct possible test (that I can think of) for testing the hypothesis that there is a connection between how one imitates and how one ``generalizes.''%except maybe a token-by-token DiD type model
Given that it is not significant, it would seem to me that there is at least some justification for hunting around for things that might affect generalization, given that imitation alone doesn't cut it... \hl{is that bad science?}%also, why am I only talking about VOT here?

So, since we know that consistently lengthening (or shortening) your VOT when shadowing alone isn't a significant predictor of when these participants would lengthen their post-test VOTs, I ran a different model that tried to predict how people would change their VOT in the post-test based on the factors that I care about... That is to say, their imitation score, broken apart dominance scores and IAT scores.

\hl{Hold up... The way I've been thinking and writing about this this evening is as if I'm trying to predict one generalization score per speaker, but that is} \begin{enumerate}
\item \hl{not directly comparable to the Mandarinization score models, which are token-by-token, and}
\item \hl{silly cuz of something else that I thought of a second ago but can't remember now.}
\end{enumerate}


\hl{I also need to talk about the models where I'm trying to predict how they changed the other post-test variables, not just how they changed VOT.}


\section{Discussion-y stuff}
\hl{I need to talk about the fact that Trudgill is assuming monodialectalism, while that's not the case in NJ.})

This makes sense, to a degree, because there's plenty of evidence that people will change their speech significantly in all sorts of interactions, including in shadowing contexts like the one used in this experiment (\hl{CITATIONS}), and not only that they'll accommodate, but that they'll accommodate across dialects \citep{delvaux2007influence,babel2010dialect,clopper2014sound}. (\hl{Make sure each of these is actually relevant and then figure out \textit{why} it's relevant and put in any necessary detail here.}) BUT! At the same time that we know these things about accommodation, Trudgill notes (rather vaguely) in his theory that basically there's just a point at which an individual has encountered ``enough'' of the target dialect to begin accommodating in the long-term (\hl{CITATION}), but he doesn't suggest how much that is or how he knows it to be true (\hl{to the best of my recollection}). So, what we saw in the experiment was the robustness of interpersonal accommodation attested in the literature, but may \textit{not} have seen long-term accommodation experiment internally because we just didn't hit that threshold of ``enough.''

To determine whether interpersonal accommodation is what's 

Because short-term accommodation is presented in the theory as a necessary prerequisite to long-term accommodation (\hl{MAKE SURE THIS IS A DEFENSIBLE REPRESENTATION OF THE THEORY}), we need to know whether short-term accommodation has in fact taken place before we can say whether the dynamic has been recreated. This is going to be discussed in section \ref{sec:doTheyShadow}.

In addition to knowing whether people accommodated in Mandarin during the shadowing block, we need to know if that accommodation led to ``long-term accommodation'' in the post-test block. If my participants changed their 

Because we know that different people accommodate to different degrees (\hl{CITATION}), it is necessary to determine the degree to which participants engage in accommodative behavior in the short-term within the context of the experiment. I'll discuss this question both in terms of the group of participants as a whole (i.e. the models that go response variable (VOTdur and A1-P0) ~ condition), and also as an individual quality (i.e. the models that give ``imitation scores'' for everyone).

We would expect that if, in general, the group were to display long-term accommodation, then they would also accommodate in the short term. accommodates in the short-term, we 

More nitty-gritty questions I'm going to answer include:
\begin{enumerate}
\item If all participants are considered together, are there significant changes in participant behavior during the shadowing portion of the experiment? In other words, do the participants---as a group---shadow the recordings that I played for them. If they do, then that suggests that... I will discuss the answer to this question both in terms of the length of participant VOTs and their A1-P0 values. Answering this allows us to determine whether there has been significant movement away from the Mandarin baseline, either towards or away from the shadowing model.
\item Are there predictable relationships between how much individuals shadow (``imitation score'')%or ``Difference in Distance''
and any of the linguistic, \hl{socio-psychological}, or demographic factors that have been measured as a part of this experiment? In short, can we explain how various factors contribute to the way that individuals shadow?%Wait... is this what I actually care about at all? Why does it matter if they 
\end{enumerate}
The quick and dirty answers to these questions are ``yes,'' and ``yes.'' %actually, now I'm not sure that I know that the answer to question 2 is yes. I'm not sure I actually ran the model
The \textit{reason} I'm answering these questions in this chapter is cuz if I'm going to replicate long-term accommodation \citep{trudgill1986dialects} in the lab, it's important that there's some \textit{short-term} change to serve as instigator (that's for the first question). On top of that, it's of both theoretical and practical interest to be able to explain why %be careful using ``why'' as opposed to saying something like ``how factors contribute.'' Think about correlation vs. causation sensitivity.
people behave the way that they do, at least if we're planning on being able to predict how sound change progresses through a society from person to person as Trudgill's theory suggests we should be able to do (that's the second question).%why is it interesting to know both how VOT changes in response to block/condition, AND how imitation changes in response to demo and other factors. Possibly useful to introduce these things in the intros to section about how the group behaves overall (currently 4.2) and how individual behavior is conditioned (currently 4.3)

% rebecca makes comment that there aren't methods bits of this chapter, so when you turn it in for jobs it'll be much harder for them to interpret, so you can think about at least adding like a little preamble that's like ``this is what they did, who they were,'' etc.

I should note also that I looked at changes in \hl{...something...}.

The interlocutor in this case is a recording of a Mandarin speaker. Trudgill's model suggests that this interpersonal 

    \section{Overall Changes in Participant Behavior in the Shadowing Condition} %reword for clarity
    \label{sec:doTheyShadow}
    Just as a reminder of how this works, I had participants listen to hyper-Mandarinized recordings of the ``extended [p\textsuperscript{h}] words with VOTs that had been doubled from their natural length and productions of the ``nasal coda'' words, where the person producing the stimuli had been careful to produce nasal codas in every word. The recordings that participants shadowed were all of words from the production word list (appendix \ref{appendix:ProductionList}), so I already had baseline measures for participants pronunciations and could determine whether and how their pronunciations had changed. Participants were instructed to ``quickly use Mandarin to clearly repeat the words you hear'' in the recordings. The idea was that that they would accommodate to the \textipa{\"uber}-Mandarinized recordings by shifting their Mandarin pronunciations towards those of the recordings.
    
    Remember, Mandarin baseline VOT was 93 milliseconds, and nasal coda production rates were only like 40\%-ish (chapter \ref{baselinechapter}), but my stimuli had and average VOT of 184 milliseconds (nearly double the participant baseline) and a nasal coda presence rate of 100\%, which we'd expect (\hl{I think?}) to lower nasality throughout the course of the vowel cuz it's shifted the locus of the locus of the velum lowering gestrure to outside the vowel bit of the word. What that all means is that we're going to expect people to lengthen their VOT and lower their A1-P0 in the shadowing condition, and that's exactly what they did. Changes in both of the shadowing variables as measured across all participants were significant.
    
    \hl{Throw some stuff in here about the difference between what predicts VOT vs NAS shadowing}

        \subsection{VOT}
         A likelihood ratio test of two linear mixed effects models confirms that experimental condition (baseline vs. shadowing) has a significant effect on the duration of VOT ($\chi^2 (1) = 79.687$, $ p < 2.2e-16$), specifically extending it by 6 ms .

        \subsection{Nasal Coda Presence and Duration}
        Nasal codas are a bit trickier to talk about, for several reasons. First, one of the variables under consideration here is ``presence'' of nasal coda, which is actually an impressionistic judgement of whether there's an alveolar nasal coda on the syllables being examined. To determine whether there was or not, I'd listen to the...%come up with cogent description of what your standards were for deciding whether there was a coda or not. Notes:  Did there seem to be a closure? Was it alveolar sounding? Was it voiced? etc... It would have been a lot easier to do this bit if I'd had like a nasal airflow mask, but I didn't, soooo......
        I also measured the durations of the cases for which I determined that there were codas. To measure the duration, I took the interval between what sounded/looked (in the spectrogram and waveform) like the closure and measured up until Praat's automatic pitch tracking dropped out when looking at the spectrogram with a visible duration of like 0.3 to 0.5 seconds. %That's true at least for like the last 10 participants maybe... I actually came up with the pitch tracker standard pretty late, which is problematic, but... meh. I'll try to go back and apply these standards as consistently as possible at some point.

    \section{Individual Changes in Behavior in the Shadowing Condition} %reword for clarity
    \label{sec:whyDoTheyShadow}
    In this section of the dissertation, I will make use of ``imitation scores,'' which were generated for each participant by making a within-subject linear mixed effects model that predicted PTH VOT duration by experimental block with a random effect for word. I used the t value calculated as part of those models as my participants' imitation scores, interpreting it as giving a single-number measure of the consistency with which participants changed their behavior, in what direction. Because of how they are calculated, imitation scores near zero indicate either that the participant did not diverge from their PTH pre-test values much, or that they diverged from those values but by increasing \textit{and} decreasing from it in equal measure on average. Scores that are further from zero indicate that the participant either increased (for positive scores) or decreased (for negative scores) their values with greater consistency than those closer to zero.

        \subsection{VOT}
        There was a pretty intense range of changes in behavior. Of the 30 participants being considered here, the mean change from PTH pre-test to shadowing within an individual ranged 
        from -13 ms %subject1
        to +40 ms %subject29
        for VOT. However, as noted in section \ref{sec:doTheyShadow} above, the overall tendency for the group was to increase their VOT, yielding a significant increase of 6 ms from PTH pre-test to the shadowing condition; twenty-two of the participants had positive imitation scores %I need to figure out what I'm gonna call this number and do it consistently throughout. I opted for ``PTH lengthening score'' in the prospectus… not sure how I feel about that now.
        (indicating lengthening of VOT) and 8 had negative scores (indicating shortening). 

        \subsection{Nasal Coda Presence and Duration}


    \section{Discussion: What does any of that \textit{mean}?}
    \label{sec:shadowingDiscussion}
    So this is where I'm planning on explaining the significance of each of the results broken down above. Lemme try to give a little explanation here now.

    Basically, for the first question posed in section \ref{sec:shadowingIntro} above, what we see is that, in all relevant respects, there is significant shadowing. People really do change the way that they behave when they're exposed to the Mandarin model. This is not surprising, cuz all the literature seems to suggest that there's basically this psychosocial reflex towards imitation of an interlocutor's behavior, even if the interlocutor is just a recording. That's important. It's important cuz \cite{trudgill1986dialects} says that the process for sound change is 1) people imitate members of other dialect groups as they interact with them, then 2) begin adopting those features into their own dialect in situations where there's not really like a \textit{good} reason for them to use it... like, they're not imitating, they've just imitated so much that it's like become a habit outside of contexts where there's any stimulus for the behavior. That first step is what we're showing here. It's important that I managed to make people imitate, cuz that's a prerequisite for the second step of Trudgill's model to be recreated in the lab.

    Also, in answering the second question posed in section \ref{sec:shadowingIntro} above (i.e., can we explain why people shadow the way they do?), I'm... advancing our understanding of... that? Also... cuz...

    The fact that linguistic factors seem to predict shadowing behavior relatively well %is that actually true? I need to figure out the random forest importances; check this out http://explained.ai/rf-importance/index.html
    suggests to me that there really is something to the ``psycholinguistic reflex'' thing I've been blaming imitation on. %... I think?
    For example, people are probably not consciously controlling the length of their VOT, certainly not before being exposed to the model, but nonetheless the length of their VOT in the baseline predicts quite well how people will behave during the shadowing bit.

    I probably need to say something about the ``\hl{socio-psychological}'' and demographic factors, too. 
    
    From my WSC5 poster:
    \begin{quote}
    The positive correlation established for VOT between convergence in the shadowing and post-test blocks%connect to \ref{tab:VOTpostPredictors}
    (hypothesis 3) is suggestive of the dynamic described in Trudgill’s theory.
    
    But the fact that \hl{better imitators participate less in real- world sound change (hypothesis 4; see also Pinget 2015)%connect to \ref{tab:XXXmandPredictors} tables
    , and that} the pattern does not hold between variables (hypotheses 1-4) %connect to \ref{tab:XXXpostPredictors}
    suggests that the finding may be the result of another process, like short-term susceptibility to priming, and not a direct mechanistic link between imitation and long-term sound change.
    
    The lack of change in A1-P0 from pre-test to shadowing (hypothesis 1) being followed by a significant change from pre-test to post-test (hypothesis 2) is surprising.
    
    The lack of patterning across variables is also surprising, and suggests the possibilities that either different sociolinguistic variables behave quite differently, or that the type of experimental manipulation is important.
    
    The overall picture presented by these results argues against Trudgill’s assertion of a direct, mechanistic link between interpersonal accommodation in interaction and the propagation of linguistic change.
    \end{quote}

    \pagebreak

    \section{Shadowing DiD predicts ND baseline} (lm(did.predict\$NDbaseline$\sim$did.predict\$shadowing), $p=0.0172$). If you shadowed more, it means you have a shorter ND baseline VOT (i.e., your ND is more different from Mandarin). %I might want to change this to be shadowing DiD predicting tokenms[block==1], since it's mathematically essentially equivalent (tokenms=baseline-constant) but more directly represents the point I want to make (that is, about imitation as measured by shadowing DiD predicting Mandarinization).
    I'm pretty sure this is the same conclusion that Pinget (2015) comes to in their Ch. 8. They say that worse imitators are more advanced in sound change, and I'm saying here that better imitators are less advanced in sound change. Same-same.

    ALSO! Shadowing DiD predicts PTH mandarinization (super consistently) \newline(lm(did.predict\$PTHms[did.predict\$variable==``VOT''] $\sim$ \newline did.predict\$shadowing[did.predict\$variable==``VOT'']), $p<2.2e-16$). If you shadowed more, it means you have a shorter ND (PTH?) baseline VOT (i.e., your ND (PTH?) is more different from Mandarin).

    Question: Are there differences in how Evan imitates VOT and how he imitates nasals? This is an important question cuz we expected the ``novel'' variable to show us unproblematically who was ``imitates more.''

    I need to look at imitation of VOT's correlation with all the other non-VOT variables
    
    \hl{Do the VOT and NAS variables behave differently? They seem to with respect to mandarinization, so they might for some of the stuff I talk about in this chapter. I should look into that.}
    
    \hl{In this chapter, I think I'll want to essentially ignore imitation score, cuz it's neither a predictor nor a response variable. I'm predicting duration/a1-p0/TL/etc. essentially by experimental condition.}