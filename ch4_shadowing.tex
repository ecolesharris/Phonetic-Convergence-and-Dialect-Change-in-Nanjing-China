\chapter{Experiment-internal Accommodation}
\label{internalchapter}
    
\section{Recreating the \cbat{} Dynamic in the Lab}
\label{sec:shadowingIntro}
    Main points in this chapter:
    \begin{itemize}
        \item I was trying to recreate a specific dynamic that's been suggested to be the root mechanism of contact-induced dialect change; and
        \item people \emph{do} imitate, but the imitation doesn't lead directly to dialect change in the way that the theory mentioned above suggests; but
        \item the variation in how people imitate may still be one useful factor in predicting how people participate in contact-induced sound change \IRL{} \hl{(Ch. 5 teaser)}.
    \end{itemize}

\paragraph{To the first point:}
    Peter Trudgill has long argued for the primacy of face-to-face accommodation in interaction as a mechanism of dialect mixture \citeyearpar{trudgill1986dialects, trudgill2008colonial}. His stance has also been taken up, at least in part, by scholars such as Tuten \citeyearpar{tuten2008identity}, \hl{(MORE)}. Trudgill's argument is that a speaker first adopts speech features from a donor dialect as a form of accommodation within the context of single interactions (``\sta{}''). After sufficient exposure, the same speaker begins to generalize those features into situations that don't involve interlocutors who speak the donor dialect (``\lta{}''). In other words, when you interact with someone who speaks a different dialect than you, you'll start using those other-dialect speech patterns with your other-dialect interlocutor as a form of ``\hl{quasi-automatic accommodation}'' \citep[p. ??]{trudgill2008colonial}, and then later begin to use those same speech features even with your same-dialect compatriots. % \hl{Throughout this dissertation,} I have referred to the accommodate-to dialect as the ``donor dialet'' and ``recipient'' dialects, respectively.
    This theory is sometimes known as the \cbat{} \citep{auer2005role}.\footnote{There is also a competing theory, know as ``identity projection,'' which Trudgill rebuts in ``Colonial Dialect Contact in the History of European Languages'' \citeyearpar{trudgill2008colonial}. That theory might show up when I'm talking about LN, but I'm not sure at the moment.}
    
    \hl{add discussion of} the problematic aspects of using the terms ``\sla{},'' in the context of the implication that one is a simple extension of the other, in light of the evidence in this chapter.
    
    It is a central assumption of this theory that ``dialect contact necessarily leads to dialect mixture,'' and that ``the fundamental mechanism leading to dialect mixture is accommodation in face-to-face interaction'' \citep[p. 242-3]{trudgill2008colonial}. On top of that, the connection between such accommodation and dialect mixture is viewed as ``mechanistic''\hl{(CITATIONS)}, but empirical evidence for the specifics of how such a connection functions is difficult to come by. \cite{delvaux2007influence} have found that interpersonal accommodation can indeed manifest in a recipient dialect due to interaction with a donor dialect, and that such accommodation can persist into a post-test, though in that condition  ``the speakers came back towards their own pronunciation, but usually not completely.'' (p. 25). I'm adding to our knowledge here by testing a number of different types of variable all at once... I'm pretty sure \cite{delvaux2007influence} didn't do that. %\cite{pinget2015actuation} has suggested that how much an individual accommodates to the phonetics of an interlocutor is inversely related to how advanced that individual is in a given sound-change-in-progress, which is---at the very least---counter-intuitive in a \cbat{} context. I am unaware of any studies that show a group of speakers adopting a phonetic feature from a donor dialect into their own speech, and then showing that the same feature can persist into a recipient dialect outside of the initial accommodative context.\hl{This is no longer true, now that I have rediscovered Delvaux and Soquet. Maybe just this chapter is doing more or less the same thing they did, but then when you consider it together with the next chapter, it's pushing boundaries.} This chapter describes my attempt to do just that.
    
    %\hl{Same as above?} Because short-term accommodation is presented in the theory as a necessary prerequisite to long-term accommodation (\hl{MAKE SURE THIS IS A DEFENSIBLE REPRESENTATION OF THE THEORY}), we need to know whether short-term accommodation has in fact taken place before we can say whether the dynamic has been recreated. This is going to be discussed in section \ref{sec:doTheyShadow}.

    We know that short-term accommodation is prevalent in dyadic interaction \IRL{} \hl{(CITATIONS)}, but also fairly robust in the lab, including in shadowing contexts like the one used in this experiment \citep{nielsen2008word,pardo2006phonetic,zellou2016phonetic}. Long-term accommodation has also been convincingly observed both in the wild \hl{(CITATIONS, people adopting aspects of local accents in new countries that they move to:)}\citep{chambers1992dialect, kerswill2000creating} and in the laboratory \hl{(CITATIONS?)}. There's also plenty of evidence that not only will people change their speech significantly in all sorts of interactions, but that they'll accommodate across dialects \citep{delvaux2007influence,babel2010dialect,clopper2014sound}. And so, the assumption that \sla{} must be linked is reasonable, as is the hypothesis that it is a mechanism for contact-induced dialect change, but the questions of whether short-term accommodation \emph{leads} to long-term accommodation, and does so \emph{mechanistically} deserve to be carefully examined. 
    
    \hl{This was largely cut from below so may not quite fit in the prose, but this feels like a good spot to argue for using labphon methods to look at this type of question} \cite{delvaux2007influence} \hl{(MORE CITATIONS)} all utilized experimental protocols to elicit short and long-term accommodation, and their results generally indicate that \xxxxx{}. \hl{Commentary about the shadowing protocol's parallel's to the real world.} The changes that can be elicited in the lab are reasonable experimental parallels for the specific aspects of the real-world \sla{} dynamic being investigated here. This protocol is analogous to a person going out into the real world, having a conversation with someone who speaks a donor dialect, and then going back into the context of the recipient dialect.
    
    Because participants proceeded immediately from recording the dialect baselines to shadowing \annie{} and then again to the \ND{} post-test, significant changes to the group's pronunciation in the shadowing and post-test blocks are unlikely to come from any source other than exposure to \annie{}. %During the experiment, participants' exposure to both their own baseline Mandarin and \annie's hyper-standard Mandarin \hl{cause changes that persist} into in the \ND{} post-test. That's exactly the dynamic we're investigating \IRL.\footnote{\hl{Is that true?} Am I comfortable saying that their \ND{} was ``caused'' to change by this exposure? Or that the apparent changes to their dialect are ``persisting'' from what happens in the shadowing block?} While there are plenty of reasons that an individual might change their pronunciation from the examples of a persistent change in one's speech style after exposure to a different style.
    If the group as a whole, then, were to first accommodate to at least one specific speech feature of the model talker and then carry that same pattern of accommodation back into their Nanjing dialect in the absence of the model, then we have successfully gathered empirical evidence of the short-into-long dynamic described in \cbat{}.
    
    \hl{I probably need some discussion of whether it's reasonable to expect to see changes at the group level, rather than only at the individual, since that's what I'm testing with these models, but it doesn't show up \textit{everywhere} that I expect it. I'm saying that ``imitation is robust,'' but it'd prolly be good to specify the set of features and circumstances across which it is robust, and let people know why it makes sense to expect to see it in a group of 30 people. I also feel like it's kinda problematic that the analysis isn't paired for individuals across experimental blocks. Like... why group as a whole and not individuals? [R: you're justified in doing group stuff just cuz you're interested in learning ``do people do a thing''which you gotta do as group statistics.]}
    
    The original formulation of Trudgill's theory notes (rather vaguely) that \hl{``if accommodation [...] is frequent enough, then that feature may become a permanent part of a speaker's accent or dialect''} \citeyearpar[p. 40]{trudgill1986dialects}. Basically, the theory holds that there is a point at which an individual has encountered enough of the donor dialect to begin accommodating in the long-term, but Trudgill does not suggest how much exactly is enough, nor does he explain how he knows this to be true (\hl{to the best of my recollection}). The implication, in any case, is that there is a standard progression in contact-induced dialect change situations from exposure, to short-term, to long-term accommodation. It seems pretty obvious to me that you can't have \emph{any} sort of accommodation without exposure, but the preceding formulation of \cbat{} implies that one should not see \lta{} without first seeing \sta{}. The theory, therefore, leads us to predict that \emph{if} we see long-term accommodation in a given linguistic variable, it should only be when that variable has also been accommodated to in the short-term. This, however, is not what we see in the present experiment. We do see some predicted instances of interpersonal accommodation in the short-term, as well as one instance of predicted long-term accommodation, but in no case do we see evidence that short- inevitably leads to long-, nor that when we see long- it must have been preceded by short. What follows is first a brief review of the experimental methodology, with an eye to explaining its relevance to the theory, then a description of the results of the experiment, and finally a discussion of the implications of those results for \cbat{}. %Trudgill's original theory is vague on when exactly speakers are supposed to switch from short- to long-term accommodation, saying only that...At the same time that we know these things about accommodation, Trudgill... , and to show that while we see evidence of both \sla{}, we see no... experiment internally because we just didn't hit that threshold of ``enough.''

    % rebecca makes the comment that there aren't methods bits of this chapter, so when you turn it in for jobs it'll be much harder for them to interpret, so you can think about at least adding like a little preamble that's like ``this is what they did, who they were,'' etc.
    
\section{A Methodological Reminder}
    As mentioned in Chapter \ref{methodchapter}, thirty participants who are bidialectal in Mandarin and \ND{} Chinese recorded baseline pronunciations of a list of 150 words, first for \ND{} and then for Mandarin. The word list included 5 linguistic variables with 30 words each; see Appendix \ref{appendix:ProductionList} for the entire list. Participants then shadowed a Mandarin model talker producing manipulated versions of the words for two of those linguistic variables, twice per word. Participants were not explicitly instructed to imitate the model talker, but to ``quickly use Mandarin to clearly repeat the words you hear.'' Finally, participants rerecorded the entire 150 word list in a \ND{} post-test.
    
    To create the stimuli for the shadowing block, \annie{} produced natural tokens of the extended [p\textsuperscript{h}] and nasal coda words, with the special instruction to be careful to produce nasal codas in every nasal coda word. Each extended [p\textsuperscript{h}] token was later digitally manipulated, doubling its VOT duration (post-manipulation $\mu = 184$ ms). The nasal coda words required no further manipulation, as the careful inclusion of codas resulted in a nasal coda presence rate of 100\% and \hl{presumably} reduced the nasality of the preceding vowel by shifting the timing of the velum-lowering nasal gesture out of the vowel and into the coda \citep{beddor2009coarticulatory}. \hl{I'm not sure if I will have described this beddor-based argument in detail yet at this point. If I need to but haven't in earlier chapters, I'll put it here later.}
    
    \paragraph{Heads-up:} If the numbers in the following paragraph are hard to keep track of, feel free to check out table \ref{tab:shadVarbSumm} for a tidier visual representation. Here we go...
     
    Recall from Chapter \ref{baselinechapter} that baseline Mandarin VOT durations for the he extended [p\super{h}] words ($\mu = 93$ ms) are significantly longer than those of \ND{} ($\mu = 83$ ms), and that baseline Mandarin's rate of presence of nasal codas (41.5\%) was significantly higher than that of \ND{} (4.5\%), which has mostly replaced the [\ae n] rhyme with a fully nasal [\~{\ae}]. Also recall that Mandarin's baseline A1-P0 ($\mu = -2.677$ dB) is higher than that of Nanjing dialect ($\mu = -3.834$ dB), meaning essentially that Mandarin is the less nasal of the two dialects overall, which fits with the greater presence of nasal codas. Because of the significant differences between the model, participant Mandarin baselines, and participant \ND{} baselines, the manipulations described above had the effect of creating hyper-Mandarinized versions of the extended [p\textsuperscript{h}] and nasal coda words along three dimensions of measurement (VOT duration, nasal coda presence rate, and vowel nasality). By having participants shadow hyper-Mandarinized versions of a subset of the variables represented in the production list, I gave them ample opportunity to engage in short-term accommodation to those variables within a donor dialect context. The robustness of imitation within prior experimental research that uses a shadowing paradigm suggests that I should expect participants to significantly lengthen their VOT, increase their nasal coda production rate, and raise their A1-P0 in the Mandarin shadowing condition; also, the theory suggests that they should then carry those changes over into the \ND{} post-test as well.

    \hl{I wanted to say more here about like how cuz these are already dialectal differences, and particularly cuz they're extreme versions of these differences, the varbs should be more likely to be shadowed, or something like that, but I don't have citation to back that up. I guess one thing I could say is that logically, given that the dialects already vary in these respects, participants should be able to perceive and hopefully produce the hyper-mandarinized versions, and so if there weren't any shadowing result it wouldn't be because the stimuli weren't perc-prod-able... though actually, now that I think about it, the only measure that didn't show shadowing (a1p0) I actually don't know whether Annie's productions were hyper-mandarinized in that respect or not. [R: Maybe relevant stuff re language distance in Delvaux Soquet and whoever... Yu?... et al. about the like dialects of korean or whatever it was. Might also want to check out Flege about U-shaped learning curve.]}
     
\begin{table}[]
    \centering
    \begin{tabular}{|c|c c c|}
        \hline
                                 & Model & PTH    & ND \\
        \hline
        VOT Duration (ms)        & 184   & 93     & 83 \\
        Nasal Coda Presence (\%) & 100   & 41.5   & 4.5 \\
        A1-P0 (dB)               & N/A   & -2.677 & -3.834 \\
        \hline
    \end{tabular}
    \caption{Summary of shadowing variables for various speakers/dialects}
    \label{tab:shadVarbSumm}
\end{table}

    Finally, recall that there were also significant differences between the dialect baselines for each of the other three linguistic variables examined in this dissertation (IY, IE, and LN). These variables were held out of the shadowing portion of the experiment for three reasons. The first reason is that if participants were to shadow all five variables twice, the total time required to participate in the experiment would have been intolerably long; and even if they shadowed each word only once, the time required would still be longer than the roughly 90 minutes that participants needed for the current protocol. Additionally, if each variable were shadowed only once, participant exposure to the two easily manipulable variables---VOT and nasal codas---would also have been significantly reduced, potentially reducing the likelihood of both \sla{}.
    
    The third reason for holding out these variables from the shadowing block is that doing so created an opportunity to show whether linguistic variables that \emph{are} shadowed and those that are \emph{not} behave differently. While this version of \cbat{} does not make strong predictions as to the direction of change from baseline to post-test for the non-shadowed variables, positive evidence of long-term accommodation towards Mandarin norms in the \ND{} post-test by both the shadowed and non-shadowed variables would suggest that a version of \cbat{} which maintains that \sta{} is a prerequisite for long- has overstated its case. In this version of \cbat{}, it should not be possible for features to which speakers are not exposed---and to which they therefore cannot accommodate---to behave in a manner consistent with with those to which they \emph{are} exposed. We will see in the results and discussion below that these held-out variables provided neither a particularly clear rebuke of nor obvious support for any aspect of \cbat{}, but their elision is still justified on practical grounds.
    
    \hl{I don't know how defensible people will think it is that I'm calling my post-test long-term accommodation, *particularly* given that the one interesting post-test case was *not* preceded by short-term accommodation, at least not based on the model we settled on. Like, I know that's interesting, but I don't quite know how to frame it. I'm worried that people will think it's definitive of long-term accommodation that it follows short-, just definitionally. [R: It's admirable to try not to confuse people. Perhaps more careful terminology is good. If you define it, it's prolly okay, but it DOES make it sound like long- necessarily follows short. It IS good not to confuse people, but it could be a good opportunity to discuss a) the terminology and b) whether lta is actually an extension of sta... which you're arguing it's not.]}

\section{Analyses and Results}
\label{sec:shadowingResults}
\hl{I may need to include in here an argument for just looking at raw acoustic measures, rather than DiD.}

\paragraph{To the second point:}
    The theoretical dynamic described in \textit{Dialects in Contact} \citep{trudgill1986dialects} doesn't quite pan out in this experiment, but it fails to do so in a pretty interesting way that suggests Trudgill's model is too simple.

    The measures I used to look for changes in my participants' speech over the course of the experiment were:
    \begin{enumerate}
        \item VOT duration for the extended [p\super{h}] words,
        \item rate of presence of nasal codas for the nasal coda words,
        \item A1-P0 as measured at five time points throughout the vowel, also for the nasal coda words,
        \item F1$\times$F2 vowel trajectory length (a.k.a. ``degree of diphthongization'') for the IE words,
        \item midpoint F3 values for the LN words, and
        \item midpoint F3 values for the IY words.
    \end{enumerate}
    
    The particular implementation of \cbat{} being tested here makes a number of important predictions about how these measures should behave. % In the post-test bit, I wanted to measure how much people's \ND{} changed after exposure to Mandarin. I'm measuring several different pre-test-to-post-test changes in \ND{} pronunciation here:
    %\begin{enumerate}
    %    \item duration of VOT (``extended [p\super{h}] words''),
    %    \item value of A1-P0 at 5 points throughout the vowel (nasality, [\~{\ae}]/[{\ae n}] words),
    %    \item F1-F2 formant trajectory along 4 segments of the vowel, which I generally refer to as ``degree of diphthongization,''( \textipa{[e]/[iE]} words),
    %    \item F3 value at the midpoint of the vowel (``\textipa{[I]/[y]} words''), and
    %    \item F2 value at the midpoint of the consonant (``\textipa{[l]/[n]} words'').
    %\end{enumerate}
%\subsection{Hypotheses Tested}
%\label{ssec:shadowingHypotheses}
    First, for each variable that participants are exposed to, they should shift their Mandarin pronunciation towards that of \annie{} during the shadowing task. Second, after having shifted their Mandarin towards \annie{} in the shadowing context, their \ND{} pronunciations should---provided sufficient exposure---also become more like those of \annie{}. Finally, there should be no change from baseline to post-test evident in variables that are not shadowed. \hl{This is actually a problematic prediction if I don't go through and carefully prove that there's NOTHING in the shadowing block that could cause a change in the non-shadowed variables. I'm prolly gonna walk this back later.} Therefore, the specific predictions being made about the shadowing condition are that:
    \begin{enumerate}
        %\item The model's VOT will be different from (longer    than) the participants' PTH VOT \hl{(this will actually be covered in Ch 3)};
        \item the group as a whole will significantly lengthen their VOT when they shadow; \label{hyp:VOT_longer_in_shad}
        \item the group as a whole will significantly increase their nasal coda production rate during shadowing; and \label{hyp:more_codas_in_shad}
        \item the group as a whole will significantly increase overall A1-P0 across the vowel during shadowing. \label{hyp:a1p0_higher_in_shad}
    \end{enumerate}
    Likewise, we expect that the shadowed variables will again shift towards \annie{}'s pronunciation in the \ND{} post-test, but that there will be no change in the non-shadowed variables. Hence, we predict that:
    \begin{enumerate}
        \setcounter{enumi}{3}
        \item the group as a whole will significantly lengthen their VOT in the post-test; \label{hyp:vot_longer_in_post}
        \item the group as a whole will significantly increase their nasal coda production in the post-test; \label{hyp:more_coda_in_post}
        \item the group as a whole will significantly increase overall A1-P0 across the vowel in the ND post-test; \label{hyp:a1p0_higher_in_post}
        \item the group as a whole will \emph{not} significantly change their degree of diphthongization for the IE words in the post-test; \label{hyp:ie_no_change}
        \item the group as a whole will \emph{not} significantly change their F3 for the IY words in the post-test. \label{hyp:iy_no_change}
        \item the group as a whole will \emph{not} significantly change their F3 for the LN words in the post-test; \label{hyp:ln_no_change}
    \end{enumerate}
    
    Each of these hypotheses were tested by creating a linear mixed-effects model predicting response variable by experimental condition and any other appropriate predictors for the data from experimental blocks relevant to the question. Each model was then subjected to likelihood ratio tests that compared the full model with null models that omitted single fixed effect terms (e.g., experimental condition) to determine whether the term's inclusion in the analysis made a significant difference to the behavior of the model. Details %of the results of these tests are in the results section (\ref{sec:shadowingResults}) 
    below.

\subsection{The Shadowed Variables}
\label{ssec:votnasResults}
    Here are the results of each of the shadowed-variables. As a reminder, the three measurements taken from the shadowed variables were duration of VOT, nasal coda presence, and A1-P0 as measured at five points throughout the vowel.
    
    %The first part of this worked out great; as a group,...
    For VOT, participants behaved largely as expected during the shadowing block. Individually, there was some variation in the magnitude and direction of changes in behavior, but because the goal of this chapter is to examine the plausibility of \cbat{} as a mechanism for society-wide language change, it makes the most sense to first consider the group as a whole, and return to this individual-level variation in Chapter \ref{microcosmchapter}, where it will be used as a predictor for both experiment-internal and -external participation in sound change. For now, it will suffice to say that twenty-two participants lengthened their mean VOT during the shadowing block, converging towards \annie{} relative to their baseline pronunciation, and 8 participants diverged from \annie{} by shortening their average shadowing VOT relative to their baseline. The convergers' block averages increased anywhere from $+0.9$ ms to $+40.2$ ms, and the divergers' decreased by anywhere from $-0.4$ ms to $-13.1$ ms. %\hl{[R: The range of variation is good to include, but you also prolly wanna include some analysis of distribution (x are diverging vs y are converging on average). This can be a teaser as to the imitation score measure intro'd in Ch 5]} 
    
    When considered as a whole, however, the group significantly lengthened their VOTs while shadowing \annie{}, as expected (hypothesis \ref{hyp:VOT_longer_in_shad} above). A linear mixed effects regression predicting participant Mandarin VOTs by experimental condition (pre-test vs. shadowing) with random effects for speaker and word\footnote{Duration $\sim$ Condition + ( 1 $|$ Speaker ) + ( 1 $|$ Word ), data = Mandarin VOTs.} predicts an increase of $+6.3289$ ms $\pm 0.7036$ standard errors from the baseline ($\mu = 93$ ms) to the shadowing condition ($\mu = 99$ ms), and a likelihood ratio test\footnote{anova(VOT.PTH.condition.lmer, VOT.PTH.condition.null), AIC$_{null}$ = -13906, AIC$_{full}$ = -13984}confirmed that the data was \xxxxx{} times as likely under that model than under a null model that excluded the condition predictor; $\chi^2 (1) = 79.687$, $p < 2.2e-16$. %The overall tendency for the group was to increase their VOT, yielding a significant ; twenty-two of the participants had positive imitation scores %I need to figure out what I'm gonna call this number and do it consistently throughout. I opted for ``PTH lengthening score'' in the prospectusâ€¦ not sure how I feel about that now.
    %(indicating lengthening of VOT) and 8 had negative scores (indicating shortening). 
    The simplest interpretation of this result is that as a group, participants significantly lengthened their Mandarin VOTs during the shadowing block relative to the dialect's baseline; i.e., they engaged in short-term accommodation in the direction that we expected.
    
    In the \ND{} post-test the group's VOT did not change significantly from their \ND{} baseline pronunciations (hypothesis \ref{hyp:vot_longer_in_post}). Again, there was some variation, with 13 participants diverging from \annie{} by between $-0.9$ and $-11.5$ ms, and 17 converging by between $+0.5$ and $+19.6$ ms, but a likelihood ratio test comparing a linear mixed-effects regression predicting participant \ND{} VOTs by experimental condition (baseline vs. post-test) with random effects for speaker and word to a null model excluding the condition predictor showed no evidence of a significant difference in \ND{} VOTs between the baseline and post-test blocks; $\chi^2 (1) = 1.2861$, $p = 0.2568$. \hl{Do I need to report the estimate of the linear model here, since there's no sig diff?} This means that there is no evidence of significant lengthening of VOTs in the \ND{} post-test, and therefore no evidence that participants significantly engaged in \lta{} for this variable, even after having engaged in \sta{}. There are a number of possible explanations for why this might be, but we we will return to those in section \ref{shadowingDiscussion} below.

    %\hl{this had some stuff pasted above it. It may be useful, but will likely need editing.} And they do! At least during shadowing. A likelihood ratio test\footnote{anova(VOT.PTH.condition.lmer, VOT.PTH.condition.null), AIC$_{null}$ = -13906, AIC$_{full}$ = -13984}confirmed that the data was \xxxxx{} times as likely under a linear mixed effects regression predicting participant PTH VOTs by experimental condition (pre-test vs. shadowing) with random effects for speaker and word\footnote{Duration $\sim$ Condition + ( 1 $|$ Speaker ) + ( 1 $|$ Word ), data = Mandarin VOTs.}than under a null model (excluding the condition predictor); $\chi^2 (1) = 79.687$, $p < 2.2e-16$. The better-fitting model gives an estimate of $+6.3289$ ms $\pm 0.7036$ (std. errors) from the pre-test condition (M = 93 ms) to the shadowing condition (M = 99 ms). 

    %A likelihood ratio test of two linear mixed effects models confirms that experimental condition (baseline vs. shadowing) has a significant effect on the duration of VOT ($\chi^2 (1) = 79.687$, $ p < 2.2e-16$), specifically extending it by 6 ms.

    As with VOT, nasal coda presence %(a token-by-token binary ``there / not there'' judgement)
    shows evidence of significant \sta{} (hypothesis \ref{hyp:more_codas_in_shad}), with the group's Mandarin nasal coda presence rate rising from 41.5\% in the baseline condition to 55.4\% in the shadowing condition. A binomial generalized linear mixed-effects regression (glmer) fit by maximum likelihood (Laplace Approximation) predicting Mandarin nasal coda presence by experimental condition (baseline vs. shadowing) \hl{has a $p$-value less than $2e-16$... I don't know how to report glmer results. Rebecca says I should check out David Harper's dissertation, and Alyssa is sending it to me}. And, just as with VOT, there is no evidence of significant change in \ND{} nasal coda presence from the baseline to the post-test condition (hypothesis \ref{hyp:more_coda_in_post}). A parallel glmer has a $p$-value of $0.545$.
    
    Up to this point, things have been fairly straightforward: for both VOT and nasal coda presence, we see subjects engaging in \sta{}, but then failing to engage in \lta{}. A1-P0, however, gets interesting.
    
    First, there is no evidence of an overall change with respect to Mandarin A1-P0 from the baseline to the shadowing conditions (hypothesis \ref{hyp:a1p0_higher_in_shad}). A linear mixed-effects regression that predicted A1-P0 at five time points across the vowel by both experimental condition and time point in the vowel, with random effects for speaker and word, estimated that in the shadowing condition, any given time point would be roughly 0.1 dB higher (less nasal) than in the baseline. That's a change in the direction we expect, but a likelihood ratio test comparing the full model to a null model excluding the experimental condition predictor showed no effect of condition on the analysis; $\chi^2 (1) = 1.103$, $p = 0.2936$. In other words, there is no evidence that the participants as a group changed their A1-P0 significantly as a result of shadowing \annie{}. \hl{13 diverged between $-0.072$ and $-5.542$ dB, 17 converged between $+0.154$ and $+4.296$ dB... Too close to an even split, I guess.}
    
    However, despite this lack of \sta{}, a parallel analysis of participants' \ND{} showed that they \emph{did} change their A1-P0 for that dialect from the baseline to the post-test, and in the predicted direction (hypothesis \ref{hyp:a1p0_higher_in_post}). \hl{11 diverged between $-0.234$ and $-2.456$ (whoa... those decimals...) and 19 converged between $+0.226$ and $+2.257$.} Once again, A1-P0 measurements from five time points throughout the vowel were predicted by experimental condition and time point, with random effects for speaker and word. The same likelihood ratio test---one excluding the experimental condition predictor---showed that the data was \xxxxx{} times as likely under the full model; $\chi^2 (1) = 10.028$, $p = 0.001542$. The model estimated that for a given time point the effect of a change in experimental condition from baseline to post-test produced a 0.359 dB increase in A1-P0, that is a reduction in nasality, as expected given \annie{}'s greater inclusion of nasal codas. This is unexpected not only because there was no \sta{} in A1-P0, but there was also not an attendant long-term change in nasal coda presence in \ND{}. I'll discuss the theoretical significance of and potential reasons for these results in section \ref{shadowingDiscussion} below.

    \hl{(I'm not including all the descriptions of models with interactions and whatnot in this section about the NAS models, cuz I'm pretty sure I will have already talked about it in Ch. 3 when I talk about the differences between the dialects. If I forget when I write Ch 3, or if it turns out not to be relevant there, then I'll stick it in here later.)} %The linear model I performed two likelihood ratio tests: one between
    %\begin{itemize}
        %\item a linear mixed effects regression predicting participant PTH A1-P0s by experimental condition (pre-test vs. shadowing), measurement timepoint within the word (1-5), and the interaction between these two predictors with random effects for speaker and word,\footnote{A1-P0 $\sim$ Condition * Timepoint + ( 1 $|$ Speaker ) + ( 1 $|$ Word ). %I'm not sure what to do about the timepoint thing. I don't know if it's better to include it or deliberately leave it out
        %}and
        %\item a null model excluding the interaction\footnote{A1-P0 $\sim$ Condition + Timepoint + ( 1 $|$ Speaker ) + ( 1 $|$ Word ).}
    %\end{itemize}
    %with the result $\chi^2 (1) = 1.1143$, $p = 0.2912$, and another between
    %\begin{itemize}
        %\item the interactionless model and
        %\item a null model excluding the condition predictor \footnote{A1-P0 $\sim$ Timepoint + ( 1 $|$ Speaker ) + ( 1 $|$ Word ).}.
    %\end{itemize}
    %with the result $\chi^2 (1) = 1.0648$, $p = 0.3021$.
    
    %These likelihood ratio tests both failed to reject the null hypothesis that the models were not significantly different, and so I conclude that neither experimental condition nor the interaction between condition and timepoint have any effect on Mandarin A1-P0. Practically, this means that there was no difference in the overall nasality of participant vowels across conditions, nor between the nasality of the vowel at a given timepoint across conditions (i.e., the locus of their nasality didn't shift to a different point in the vowel). These results are both contrary to expectations, given that greater presence of nasal codas in the shadowing condition should shift the nasality out of the vowel and into the coda, reducing both overall nasality and nasality early in the vowel specifically. \hl{The fact that neither of these things happened even though I judged there to be significantly more codas in the shadowing condition suggests that participants may have imitated presence of the oral gesture without imitating the timing of the nasal gesture. [This is perhaps a point for an ASA paper, rather than the dissertation.]}

    %A1-P0 did change between the pre- and post-test conditions. A likelihood ratio test\footnote{anova(NAS.ND.condition.lmer, NAS.ND.condition.null), AIC$_{null}$ = 55644, AIC$_{full}$ = 55636}confirmed that the data was \xxxxx{} times as likely under a linear mixed effects regression predicting participant \ND{} A1-P0s by experimental condition (pre-test vs. post-test) \hl{and timepoint (1-5)} with random effects for speaker and word\footnote{A1-P0 $\sim$ Condition + Timepoint + ( 1 $|$ Speaker ) + ( 1 $|$ Word ), data = \ND{} A1-P0s.}than under a null model (excluding the condition predictor); $\chi^2 (1) = 9.8995$, $p = 0.001653$. The better-fitting model gives an estimate of $+0.3571$ dB $\pm 0.1135$ (std. errors) from the pre-test condition ($\mu = -3.83$ dB) to the post-test condition ($\mu = -3.47$ dB), which we're taking to mean an overall reduction in nasality in the vowel. This is the direction of change we'd expect to be associated with greater presence of nasal codas, but is surprising given the fact that there was no significant change in Mandarin A1-P0 from the pre-test to the shadowing conditions. A separate likelihood ratio test ($\chi^2 (1)=1.1143$, $p=0.2912$) between a model including an interaction between condition and timepoint failed to reject the null hypothesis that condition has no effect on the A1-P0 values of particular timepoints, meaning that there was no difference in the overall shape of the A1-P0 curve, just that it shifted upward between the experimental conditions.
    
\subsection{The Non-shadowed Variables}
\label{ssec:nonshadResults}
    As expected, neither \textipa{[e]/[iE]} nor \textipa{[i]/[y]} changed for the group as a whole (hypotheses \ref{hyp:ie_no_change} and \ref{hyp:iy_no_change}, respectively). This is based on the same type of lmer-based likelihood ratio test as described for the shadowed variables above. IE's likelihood ratio test said $\chi^2 (1) = 0.0295$, $p = 0.8636$, and IY's said $\chi^2 (1) = 0.0072$, $p = 0.9322$. 
    
    Participant behavior in the \textipa{[l]/[n]} words, however, did change for the group as a whole between the pre-test and the post-test, even though there was no exposure to manipulated versions of this particular feature. A likelihood ratio test\footnote{anova(LN.ND.condition.lmer, LN.ND.condition.null), AIC$_{null}$ = \hl{26568}, AIC$_{full}$ = \hl{26559}}confirmed that the data was \xxxxx{} times as likely under a linear mixed effects regression predicting participant \ND{} F3s by experimental condition with random effects for speaker and word\footnote{F2 $\sim$ Condition + ( 1 $|$ Speaker ) + ( 1 $|$ Word ).}than under a null model that excluded the condition predictor; $\chi^2 (1) = 11.113$, $p = 0.0008574$. The better-fitting model gives an estimate of $+55.09$ Hz $\pm 16.50$ standard errors from the pre-test condition (\hl{$\mu = 2898$ Hz}) to the post-test condition (\hl{$\mu = 2955$ Hz}). This change is contrary to our prediction that there should be no change in a variable to which the participants are not exposed during the shadowing block, but is also interesting in that it is a change \emph{away} from Mandarin norms. %my impressionistic labels say that there are more ``l'' sounding things in the post-test, so that's good. This matches.
    
    Now lets discuss what all of those results actually mean for the theory.

\section{Discussion}
\label{shadowingDiscussion}
    The purpose of this chapter has been to answer \hl{question (1) } from \hl{the introduction to this chapter above}. What we have seen is that both \sla{} occur to a significant degree at various points in the experiment, but that the relationships between those instances of \sla{} are not as implied by \cbat{}. Among the shadowed variables, for which \cbat{} predicts a progression from short- to \lta{}, we see evidence of \sta{} for two of our measures, but no evidence that they progress to \lta{}. For the third, we see no evidence of \sta{}, but regardless find our predicted change to have taken place in the long-term. Additionally, in the non-shadowed variables we see a change in one variable to which participants were not exposed in any way that should elicit such changes.
    
    All in all, the implementation of \cbat{} being investigated here doesn't cut the mustard. According to the version of \cbat{} that we've described above, the process for sound change is 1) people imitate members of other dialect groups as they interact with them, then 2) begin adopting those features into their own dialect in situations where there's not really like a \textit{good} reason for them to use it... like, they're not imitating, they've just imitated so much that it's like become a habit outside of contexts where there's any stimulus for the behavior. That first step is what we're showing here, that people do in fact imitate in interaction. That's not new, but it's important in the context of this experiment because \cbat{} implies that the first step is a \emph{prerequisite} for the second step---that is, \lta{}---to occur either \IRL{} or in the lab.

    The group-level shifts in VOT and nasal coda presence during Mandarin shadowing and in A1-P0 during the \ND{} post-test as individual facts are all predicted by a theory that says exposure to a donor dialect's speech features must inevitably lead to both short- and long-term structural convergence in the recipient dialect via accommodation in interaction. However, the specific claim in \cbat{} that ``\hl{[quote about mechanical, inevitable, and \textbf{sequential} progress from STA to LTA]}'' leads us to predict that A1-P0's \lta{} should have followed \sta{}, and---given that exposure to \annie{}'s A1-P0 was sufficient to induce \lta{} in that variable---that VOT and nasal coda presence should have progressed to \lta{} after we saw them do short-. Neither of these things came to pass.
    
    While it's possible that any number of factors could encourage sound change over the course of a real-world interaction, changes in pronunciation during these two blocks of the experiment that are significant at the group level are unlikely to have come from any source other than exposure to \annie{}. \hl{Expand this re: why we should see the specific patterns we do.}
    
    \hl{Prolly wanna get rid of this.} \cbat{} fails to account for the lack of patterning across \emph{either} the set of shadowed variables \emph{or} the set of non-shadowed variables. Within these sets, you'd expect all linguistic variables to behave the same, but the shadowed variables have different patterns of \sla{}, as described in the paragraph above, and two of the non-shadowed variables did not change at all, while one actually diverged from donor dialect norms.
    
    \hl{[I don't think either of the last two statements  above (about CBAT and what we'd expect, not about my results) are defensible. The first is a misrepresentation of CBATs positions and the second is a misrepresentation of the state of the field. Trudgill has that whole thing about ``is accommodation uniform,'' which he answers in the negative super early on (1986 pp. 9 ``I did accommodate to my informants in the case of (t), I did \textit{not} accommodate to them in my pronunciation of (}\textipa{A}\hl{:)'' emphasis in original.), and we know that some things are more imitable than others.]} 
    
    %should also show evidence of  what we'd expect, and likewise the change in  that we see in the \ND{} post-test is also predicted by  given subjects' exposure to \annie{} and  see given the model talker's careful inclusion of codas in the nasal coda words, the nasal coda words, but it is unexpected. Likewise, cuz we know that people imitate fine phonetic detail in situations like these (\hl{CITATIONS}), and they had plenty of room to imitate given \annie{}'s ridiculously long VOTs. The lack of generalization isn't necessarily surprising, because no one has established empirically that that's how things work, and even if that \textit{is} how things work, it's possible that exposure to my edited VOTs was too brief or that the VOTs themselves were too outlandish to inspire generalization.

    However, the NAS results aren't exactly what I would have predicted. Because of the difference in impressionistic nasal coda presence percepts for the Mandarin pre-test vs. shadowing data, I would have expected that A1-P0 would be different in the shadowing condition, probably by being higher until later in the word. I guess I'm not sure how I would expect that to show up in the model's results, but I would have thought there'd be a difference when excluding condition. I also tried a model without condition and a model with an interaction between condition and timepoint, but all were insignificantly different from null models. Also, for WSC5 I did a thing that I probably shouldn't; specifically, I did a DiD lmer, which is problematic with nasality, cuz it's doing a direct inter-speaker comparison of the acoustics, which is apparently a no-no. I'm gonna pretend I don't know that for the time being. This is perhaps why I should switch to the nasality curve timing thing. \hl{comment on coda presence having STA but not LTA and a1p0 having LTA but not STA. Need to talk about independence of the measures (despite being caused by same manipulation) and then about the odd pattern of short and long that has become the main point of this chapter.}

    So here are the questions raised by these facts:

    \begin{enumerate}
        \item why do you get \sta{} of VOT, but not A1-P0?
        \item why do you get what looks like \lta{} for A1-P0, but not for VOT, especially given the shadowing pattern mentioned \hl{above}.
        \item \hl{why should there be an overall decrease in nasality in the post-test [\~\ae]/[\ae n] vowels if not because of a rightward shift in the locus of nasality?}
        \item why should LN diverge... or change at all for that matter? (hyperdialectalism? trudgill 1986 pp. 65-70ish... maybe not, cuz it's where expected.)
    \end{enumerate}

    When shadowing the model talker's extended VOT in Mandarin, participants did accommodate, lengthening their own VOTs by 6 ms on average from their Mandarin baseline ($p < 2.2e-16$). They did not, however, significantly change their \ND{} VOTs in the post-test, i.e. they failed to generalize significant group-wide short-term accommodation into significant group-wide long-term accommodation.

    There are a number of possible explanations for that---e.g., exposure to the Mandarin shadowing model was insufficient to induce long-term convergence---At the same time, while they also failed to shadow A1-P0, but \emph{did} change it in the post-test.

    The results in section \ref{sec:shadowingResults} above indicate that:
    \begin{enumerate}
        %\item participant baseline PTH VOTs were significantly shorter than the model's artificially extended VOTs (i.e., there was room for them to shadow VOT), \hl{and participant baseline PTH nasal peaks were significantly earlier than the model's as well};
        \item participants displayed an overall shift towards longer Mandarin VOTs and more present nasal codas when shadowing the model speaker's manipulated tokens (i.e., they shadowed), but didn't display an overall shift in their \ND{} VOTs or nasal codas in the post-test (i.e., they didn't seem to ``generalize'' the change we saw in the shadowing block); and
        \item participants did \textit{not} display an overall shift in their Mandarin A1-P0s when shadowing but \textit{did} change their \ND{} A1-P0 from the pre-test to the post-test blocks, which is the opposite pattern of VOT and nasal codas; and
        \item participants did not change their behavior from pre- to post-test for \textipa{[e]/[iE]} or \textipa{[I]/[y]}, but \textit{did} for \textipa{[l]/[n]}, despite not having been exposed to a shadowing model for any of these last three variables (i.e., the non-shadowed variables behave inconsistently), and did so by diverging.
    \end{enumerate}
    \hl{This list is redundant with prose above, but maybe useful to keep for later.}

    The lack of patterning across variables is also surprising, and suggests the possibilities that either different sociolinguistic variables behave quite differently, or that the type of experimental manipulation is important. \hl{this is probably relevant for both shadowed and non-shadowed varbs, but I feel like in different ways.}

    The variables that didn't get shadowed (\textipa{[e]/[iE]}, \textipa{[I]/[y]}, \textipa{[l]/[n]}) are interesting as well. In my ideal imaginary dissertation, they all would have become more Mandarinized in the post-test, which would have made it easy to be like ``Look! Interaction in Mandarin causes \ND{} to Mandarinize,''  but instead only one of the three showed that overall pattern, and the other two showed no change at all. The best explanation I can come up with for that at this point is that \ND{} speakers are (at least anecdotally) explicitly aware of the \textipa{[l]/[n]} thing in their dialect, but not \textipa{[e]/[iE]} or \textipa{[I]/[y]} (at least not on the same level), and so then either maybe they were being extra careful in the Mandarin pre-test, which then carried over into the \ND{} post-test, or they wanted to project a \ND{}-y identity after the experiment, and this was their resource. This explanation is insufficient on its own, though, because it can't explain why there's pre- post- difference in A1-P0 for \ND{}; I'm pretty sure that no one knows they're doing the ``missing nasal coda'' thing.

    Re: the lack of change in \ND{} post-test VOT and nasal coda presence, despite the change in Mandarin shadowing VOT and coda presence. It's not exactly \textit{surprising} that there was no change, but this is \textit{different} from the Mandarin pre-test to shadowing comparison, which showed a significant change between conditions. One might have expected that, because the group shadowed significantly, they would also generalize significantly. This does not turn out to be the case. This is fairly easily explained in a \cbat{} context; exposure to the Mandarin shadowing model was sufficient to induce short-term convergence, but insufficient to induce long-term generalization of that convergence. Participants in the experiment just didn't hit that magical, invisible threshold at which short- tips over into long-term accommodation. Fair enough. BUT! A1-P0 does change. \hl{more about significance of this.}
    
    We also know that, accommodation may generalize from one class of sound to another. \cite{nielsen2008word} showed that accommodation to extended VOT in words that \hl{began with} the phoneme \hl{/p/} didn't just extend the VOT in the particular words that participants heard, but also in other, unheard words that began with the same phoneme, and even to words that began with other voiceless stop consonants, such as \hl{/k/}. This suggests that it's possible---if speakers have prior exposure to the donor dialect and are willing to generalize across sufficiently broad categories of sound---that an instance of exposure to a donor dialect may cause changes in categories of sound in the recipient dialect that speaker does not directly encounter in the context of \emph{that} interaction. \hl{That's wordy as shit, but the idea isn't bad.} In other words, if I know, for example, that Mandarin has extra long VOTs in its voiceless stops, then it's possible that after interacting with a Mandarin speaker, I may lengthen my VOT in \ND{}, even if I never hear that particular Mandarin speaker produce a voiceless stop. %This sort of explanation fits well with an exemplar-based understanding of language processing; \emph{all} exemplars that are associated with Mandarin are activated to some degree by interacting in Mandarin, even if the words they represent are neither perceived nor produced in the context of the interaction. \hl{I feel like I'm opening a can here, but I'm not sure why I've chosen \textit{these} worms, specifically.} 

    The observation that accommodation to one class of sound may generalize across other classes of sound to which speakers have not been directly exposed is problematic for an understanding of contact-induced dialect change that assumes a direct, mechanistic link between short- and long-term accommodation. It does not appear damning, in that it is still possible to argue that participants are accommodating in the short-term not to \hl{/p/}, but to the feature \hl{[+extended VOT],} and therefore are straightforwardly showing short-into-long-term pattern of accommodation. However, given what we find in this experiment, namely that 1) even features that are significantly accommodated to in the short-term do not necessarily translate immediately into accommodation in the long-term, and 2) that long-term accommodation of a particular feature sometimes shows up even if you haven't seen any short-term accommodation to said feature. If people showed no evidence of a change in their Mandarin A1-P0, then what class of sound is it that they accommodated to in the shadowing block that they are now generalizing across? More abstractly, if you're going to say ``you have to have short-term accommodation before you can get long-term accommodation, but long-term accommodation that looks like it's coming from nowhere isn't really as long as there was short-term accommodation to `similar enough' sounds,'' tell me where exactly is the limit of ``similar enough?''

\subsection{Stuff about where change could have come from}
    %While it's possible that any number of factors could encourage sound change over the course of a real-world interaction, changes in pronunciation during these two blocks of the experiment that are significant at the group level are unlikely to have come from any source other than exposure to \annie{}, and so such changes are reasonable experimental parallels for the specific aspects of the real-world \sla{} dynamic being investigated here. This protocol is analogous to a person going out into the real world, having a conversation with someone who speaks a donor dialect, and then going back into the context of the recipient dialect.
    
    %Because participants proceeded immediately from recording the dialect baselines to shadowing \annie{} and then again to the \ND{} post-test. The second half of this experiment's procedure---that is, the Mandarin shadowing and \ND{} post-test---is  \hl{[E: copied part of a section of Ch} \ref{microcosmchapter}] \hl{Are generalization and Mandarinization really good parallels for real-world sound change?}  because , significant changes to the group's pronunciation in these blocks are unlikely to come from any source other than exposure to \annie{}. While there are plenty of reasons that an individual might change their pronunciation from the examples of a persistent change in one's speech style after exposure to a different style. During the experiment, participants' exposure to both their own baseline Mandarin and \annie's hyper-standard Mandarin \hl{cause changes that persist} into in the \ND{} post-test. That's exactly the dynamic we're investigating \IRL.\footnote{\hl{Is that true?} Am I comfortable saying that their \ND{} was ``caused'' to change by this exposure? Or that the apparent changes to their dialect are ``persisting'' from what happens in the shadowing block?}
    
    %My measure of Mandarinization is also good, because it's a measure of the difference in pronunciation between the two dialects, and even though it's intra-personal we can be confident that, since Nanjing dialect has been getting more and more Mandarin-y \IRL~\citep{bao1980sixty}, it's not unreasonable to assume that a lack of difference between the \ND{} and Mandarin of a speaker who self-reports fluency in both (as all participants in this experiment did) is due to the \ND{} having merged with the Mandarin, rather than the other way around. Of course, not all of the dialect features that I'm looking at here have been studied before, but \hl{[LIST OF VARIABLES]} have, and \hl{[LIST OF VARIABLES NOT YET STUDIED]} make sense cuz \hl{[EXPECTATIONS BASED ON ARTICULATORY/PHONOLOGICAL EVIDENCE]}. \hl{[R: I think the more theortical aspects of your gen/mand Q belong in your intro (not methods)]}
    
    %In both cases, change is calculated relative to the relevant dialect baseline from the first half of the experiment, and because the only opportunity for change to between the first and second half of the experiment there are no
    
    %the case of the shadowing block, any
    
    %that %The key elements of this procedure for the questions to be addressed in this chapter are the I then checked to see if they 1) accommodated while shadowing a Mandarin model talker and 2) continued to accommodate in a \ND{} post-test that did not involve \annie{}.
    
\subsection{The big reveal}
    Here's my suggestion: It's possible that the first instance of accommodation actually occurs \emph{outside} the context of the donor-recipient interaction; i.e., that the first instance of accommodation may actually be \emph{long-term} accommodation, \emph{not} short. It's possible that simply being exposed to a donor dialect, whether you accommodate to it or not during that interaction, is enough to affect your production of the recipient dialect later on. This is only a suggestion, cuz I can't prove it with this experiment, but it would be easy enough to design a different experiment to get at that.

    The fact that we never observe the pattern of short-term accommodation preceding long-term accommodation in any of the shadowed variables %connect to \ref{tab:XXXpostPredictors}
    suggests that the finding may be the result of another process, like short-term susceptibility to priming or identity projection, and not a \hl{direct mechanistic [straw-man-y]} link between imitation and long-term sound change. This experiment doesn't rule out accommodation as one factor that influences how people participate in sound change, but it's clear that \cite['s]{trudgill1986dialects} model is too simple to capture all that's going on.
    
    Fortunately, I have observed that people vary with respect to how much the participate in \sla{} in systematic ways. That's Chapter \ref{microcosmchapter}.

    Trudgill was interested in ``[a]n examination of which linguistic features are and are not changed during accommodation,'' and ``whether accommodation is a uniform process'' \citeyearpar[p. 15]{trudgill1986dialects} among other things. It turns out that phonetic accommodation is not uniform, but rather selective, in that it does not necessarily affect all sounds equally even when it happens within a speaker \citep{babel2012evidence}. We also know that different people do short-term accommodation to different degrees. \hl{(CITATIONS)... and actually, why did Trudgill ask this question? He cites Giles as saying that sometimes people converge and sometimes they diverge, sooo.... doesn't he already know the answer, at least from the perspective of inter-individual variation?}. This is important because Trudgill's original theory posits that long-out-of-short-term accommodation is the mechanism by which contact-induced dialect change occurs, and so if short-term accommodation is not uniform, then you probably shouldn't expect long-term accommodation that results from that short-term accommodation to be uniform either. \hl{This feels straw-graspy, but I was pretty sure I had a point about this before. A question for myself: when Trudgill says ``uniformly,'' what does he mean?}

%\paragraph{To the third point:}
    %It will be apparent from the results below that, despite the 

    Within the context of this experiment, we observe this pattern of a recipient dialect exhibiting predicted long-term accommodation to a linguistic variable in an unpredicted context; i.e. one that has not previously shown evidence of short-term accommodation. Trudgill's theory does explicitly acknowledge that \lta{} doesn't \emph{always} follow all instances of \sta{}.  We found that as well, in that VOT and nasal coda presence showed evidence of \sta{}, but showed no evidence of \lta{}. BUT! There is also the \hl{explicit} assumption that \lta{} must be preceded by \sta{}, and that is not what we find here.

\pagebreak
notes below
\pagebreak

%\hl{Update this paragraph} In other words, I'll be describing the link between participant shadowing and generalization, both in terms of how the group behaves and how individuals behave. I'll be describing my attempt to recreate the dynamic that Trudgill \citeyearpar{trudgill1986dialects} describes (i.e., first accommodating to an interlocutor (short-term accommodation), and then continuing to use the accommodated-to features after the interlocutor isn't there anymore (long-term accommodation).

%This chapter is more or less about whether there was any change going on within the context of the experiment.

%\hl{I should give the shadowing stuff context here and then transition into the post-test stuff.}

%\pagebreak

%This page intentionally left blank.

%\pagebreak

%Their \ND{}, however, didn't change between the pre- and post-test conditions when considered as a group.
%\footnote{Changes to ND pronunciation from ``pre-test'' to ``post-test'' condition; i.e., did they generalize as a group?:

%VOT: duration $\sim$ condition + ( 1 $|$ speaker ) + ( 1 $|$ word ), data = Mandarin VOTs

%Nasality: A1-P0 $\sim$ condition + ( 1 $|$ speaker ) + ( 1 $|$ word ), data = Mandarin A1-P0s

%\textipa{[e]/[iE]}: diphthongization $\sim$ condition + ( 1 $|$ speaker ) + ( 1 $|$ word ), data = \ND{} diphthongization measures

%\textipa{[i]/[y]}: F3 $\sim$ condition + ( 1 $|$ speaker ) + ( 1 $|$ word ), data = \ND{} F3s

%\textipa{[l]/[n]}: F2 $\sim$ condition + ( 1 $|$ speaker ) + ( 1 $|$ word ), data = \ND{} F2s

%}

%Each of these models was subjected to a likelihood ratio test (anova) comparing the full model (above) with a null model that ommitted the fixed effect term (+ condition). The results were as follows:

%VOT:

%$\chi^2 (1) = 79.687$, $p < 2.2e-16$, while $AIC_{full} = -13984$ whereas $AIC_{null} = -13906$

%So the models are significantly different, and the full model describes the data better (has a lower AIC). That means we can take what the full model says about the data seriously.

%The full model says that overall, we see a 6 ms increase in subject VOTs from the pre-test condition (mean: 83 ms) to the shadowing condition (mean: 89 ms). \hl{It probably says more that that, but that's what I know how to interpret at the moment.}

%The second bit didn't work exactly like I thought it would, because there was not a statistically significant group-wide change in participants' \ND{} \textit{after} the shadowing bit. Overall, exposure to Mandarin within the context of the experiment did not engender lasting effects in the \ND{} of the group.

\section{Discussion-y stuff}
\hl{I prolly need to talk about the fact that Trudgill is assuming monodialectalism, while that's not the case in NJ... but prolly only briefly. I'm no longer 100\% sure it's relevant.})

%In addition to knowing whether people accommodated in Mandarin during the shadowing block, we need to know if that accommodation led to ``long-term accommodation'' in the post-test block. If my participants changed their 

%I'll discuss this question both in terms of the group of participants as a whole (i.e. the models that go response variable (VOTdur and A1-P0) ~ condition), and also as an individual quality (i.e. the models that give ``imitation scores'' for everyone).

%I should note also that I looked at changes in \hl{...something...}.

%The interlocutor in this case is a recording of a Mandarin speaker. Trudgill's model suggests that this interpersonal 

    %\section{Overall Changes in Participant Behavior in the Shadowing Condition} %reword for clarity
    %\label{sec:doTheyShadow}
    %Just as a reminder of how this works, I had participants listen to hyper-Mandarinized recordings of the ``extended [p\textsuperscript{h}] words with VOTs that had been doubled from their natural length and productions of the ``nasal coda'' words, where the person producing the stimuli had been careful to produce nasal codas in every word. The recordings that participants shadowed were all of words from the production word list (appendix \ref{appendix:ProductionList}), so I already had baseline measures for participants pronunciations and could determine whether and how their pronunciations had changed. Participants were instructed to ``quickly use Mandarin to clearly repeat the words you hear'' in the recordings. The idea was that that they would accommodate to the \textipa{\"uber}-Mandarinized recordings by shifting their Mandarin pronunciations towards those of the recordings.
    
    %Remember, Mandarin baseline VOT was 93 milliseconds, and nasal coda production rates were only like 40\%-ish (chapter \ref{baselinechapter}), but my stimuli had and average VOT of 184 milliseconds (nearly double the participant baseline) and a nasal coda presence rate of 100\%, which we'd expect (\hl{I think?}) to lower nasality throughout the course of the vowel cuz it's shifted the locus of the locus of the velum lowering gestrure to outside the vowel bit of the word. What that all means is that we're going to expect people to lengthen their VOT and lower their A1-P0 in the shadowing condition, and that's exactly what they did. Changes in both of the shadowing variables as measured across all participants were significant.
    
    %\hl{Throw some stuff in here about the difference between what predicts VOT vs NAS shadowing}


        \subsection{Nasal Coda Presence and Duration}
        \hl{This prolly belongs in Ch 3} Nasal codas are a bit trickier to talk about, for several reasons. First, one of the variables under consideration here is ``presence'' of nasal coda, which is actually an impressionistic judgement of whether there's an alveolar nasal coda on the syllables being examined. To determine whether there was or not, I'd listen to the...%come up with cogent description of what your standards were for deciding whether there was a coda or not. Notes:  Did there seem to be a closure? Was it alveolar sounding? Was it voiced? etc... It would have been a lot easier to do this bit if I'd had like a nasal airflow mask, but I didn't, soooo......I also measured the durations of the cases for which I determined that there were codas. To measure the duration, I took the interval between what sounded/looked (in the spectrogram and waveform) like the closure and measured up until Praat's automatic pitch tracking dropped out when looking at the spectrogram with a visible duration of like 0.3 to 0.5 seconds. That's true at least for like the last 10 participants maybe... I actually came up with the pitch tracker standard pretty late, which is problematic, but... meh. I'll try to go back and apply these standards as consistently as possible at some point.

        \subsection{Nasal Coda Presence and Duration}


    %\section{Discussion: What does any of that \textit{mean}?}
    %\label{sec:shadowingDiscussion}
    %So this is where I'm planning on explaining the significance of each of the results broken down above. Lemme try to give a little explanation here now.
    
    From my WSC5 poster:
    \begin{quote}
    
    %But the fact that \hl{better imitators participate less in real- world sound change (hypothesis 4; see also Pinget 2015)%connect to \ref{tab:XXXmandPredictors} tables
    %, and that} 
    
    \hl{[prolly useful for discussion]} The lack of change in A1-P0 from pre-test to shadowing (hypothesis 1) being followed by a significant change from pre-test to post-test (hypothesis 2) is surprising.
    
    The overall picture presented by these results argues against Trudgillâ€™s assertion of a direct, mechanistic link between interpersonal accommodation in interaction and the propagation of linguistic change.
    \end{quote}

    %\hl{[Ch 5 stuff]}Question: Are there differences in how Evan \hl{(huh?)} imitates VOT and how he imitates nasals? This is an important question cuz we expected the ``novel'' variable to show us unproblematically who was ``imitates more.''


    
    %\hl{Do the VOT and NAS variables behave differently? They seem to with respect to mandarinization, so they might for some of the stuff I talk about in this chapter. I should look into that.}
    
    \hl{In this chapter, I think I'll want to essentially ignore imitation score, cuz it's neither a predictor nor a response variable. I'm predicting duration/a1-p0/TL/etc. essentially by experimental condition.}
    
    %Trudgill was interested in ``[a]n examination of which linguistic features are and are not changed during accommodation,'' and ``[a] study of whether accommodation is a uniform process, or whether linguistically different types of accommodation take place in the case of different speakers, different situaitons, or different relationships,'' among other things. Some of this has been addressed elsewhere, and some are addressed here. This experiment \hl{(and prolly a bunch of other experiments, like} \cite{babel2012evidence}) 
    
    \hl{[E: I don't think I need this paragraph as long as people remember from chapter three and the reminder up above that the model is significantly different from the baselines by having longer VOT, greater nasal coda presence, and \emph{probably} by being less nasal in the vowel.] As reported in Chapter }\ref{baselinechapter}\hl{, a Welch two sample \textit{t}-test shows that \annie{}'s VOT ($\mu = 184$ ms) is significantly longer than participant Mandarin baseline VOT ($\mu = 93$ ms); $t = 13.322$, $df = 29.918$, $p = 4.108e-14$. This is important cuz it means that if people are going to accommodate towards the recordings, both during the shadowing and post-test blocks, they should lengthen their VOTs.}
    
    In terms of both VOT and nasal coda presence there is significant shadowing. People really do change the way that they behave when they're exposed to \annie{}. This is not surprising, cuz all the literature seems to suggest that there's basically this psychosocial reflex towards imitation of an interlocutor's behavior, even if the interlocutor is just a recording. That's important. It's important cuz \cite{trudgill1986dialects} says that...[stuff moved up]...It's important that I managed to make people imitate, cuz  the second step of Trudgill's model to be .
    
    in its acknowledgement of some unspecified threshold of \sta{} that must be crossed before a speaker transitions to \lta{}. Fair enough.
    
    Important observation: different ling varbs will behave differently within a speaker. Trudgill says this about ``(t)'' and ``(\textipa{A}:)'' in his analysis of his own speech from an interview study (1986, pp. 9), which he blames on labovian markers (his t) which are ``subject to social class and stylistic variation'' and indicators (his \textipa{A}:) which are ``subject simply to social class variation'' (pp. 10). theres implications for this study here, but they're complex and i should be reading now.
    
    ``greater awareness'' of a sociolinguistic variable ``attaches to forms that are currently involved in linguistic change'' and others, cuz salience, unless phonotactics or other discomforts including TOO MUCH salience (trud1986 citing chambers \& trud 1980 on pp. 11, continuing thru at least pp. 17)
    
    important observation: all variation w/in my speakers may be thought of as stylistic... tho i think the distinction btween ``stylistic'' and ``language'' differences is problematic in this situation.
    
    thought: trudgill points at Nordenstam's (1979) study of swedes in norway and how they attempt to keep their varieties distinct, despite the fact that the two are basically mutually intelligible cuz they're perceived as two separate and autonomous languages, in contrast to his English English and American English stories, where the varieties ``share'' autonomy. This may be interesting to think about in an ND context, given the unidirectional proscription against speaking ND sounding PTH... tho I suppose speaking PTH sounding ND is kinda looked down upon, too. Trudgill says, perhaps relevantly, on pp. 41 that``[i]t is important to notice, though, that there is one situation where core syntax and phonology \textit{can} be influenced by the media. This is where, for example, there is considerable linguistic difference between a national standard and local dialects (such as in Italy), and individual dialect speakers have made a \textit{conscious} decision to acquire the standard. Then they may use the language of the media as a model: again, \textit{imitation} and \textit{copying} is the mechanism involved, and not accommodation.''
    
    This may not be directly relevant to the dissertation, but it might be relevant as the PhRoGers continue to consider questions of what exactly is beng imitated, and it is also a claim that strikes me as both \emph{big} and improbable: ``...during accommodation speakers do not modify their phonological systems, as such, so that they more closely resemvle those of the speakers they are accommodating to. Rather, they modify their pronunciations of \textit{particular words}, in the first instance, with some words being affected before others. Speakers' motivation, moreover, is \textit{phonetic} rather than phonological: their purpose is to make individual words sound the same as when they are pronounced by speakers of the target variety.'' \cite[p. 58]{trudgill1986dialects}
    
    Trust says ``lexical diffusion... is usually characterized (see Wang, 1969) as being `phonetically sudden and lexical gradual,''' but points out that actually at least in ``fudged'' dialects, it's both lexically and phonetically gradual. I might want to check out Wang, 1969, cuz... I forget why... in the end, he's talking about ways that speakers can accommodate, by alternating between their own variant and the donor variant, by adopting the donor variant in a limited lexical set, or by partially accommodating to the phonetics, and that these three ways can interact and co-occur. (p. 62)
    
    Things that Trudgill said that might be helpful for (speculatively) explaining the patterns of accommodation that I see during shadowing and post-test
    \begin{itemize}
        \item more salient features are the ones that are accommodated to in the real world, too, except when inhibited by ``phonotactic constraints, homonymic clash, and extra-strong salience [the last of which is basically negative stereotypes]'' (trudgill 1986, p. 38).
        \item salience seems to be due to ``\emph{contribution to phonological contrast}, relationship to orthography, \emph{degree of phonetic difference}, and different incidence of shared phonemes'' (which you can figure out by listening to pop singers, locally relevant jokes, etc. My emphasis, cuz he says they're maybe more important. trudgill 1986, p.37)
        \item from catalysts and inhibitors, he infers ``fixed routes whereby all [adult] speakers accommodating from one particular variety to another [specific variety]'' will ``acquire features from the target variety in the same order'' (trudgill 1986, p.38).
        \begin{itemize}
            \item catalysts
            \begin{itemize}
                \item salience
                \item comprehension difficulties (i.e. no one understands me unless I accommodate)
                \item phonological naturalness
            \end{itemize}
            \item Inhibitors
            \begin{itemize}
                \item \emph{extra-strong} salience
                \item (L1?) phonotactic constraints
                \item homonymic clash
            \end{itemize}
        \end{itemize}
    \end{itemize}